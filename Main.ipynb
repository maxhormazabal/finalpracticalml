{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4668",
   "metadata": {},
   "source": [
    "# Machine Learning - Final assignment\n",
    "\n",
    "**Students:**\n",
    "<hr>\n",
    "Mutaz Abueisheh</br>\n",
    "Marcelo Jose Ferrer</br>\n",
    "Maximiliano Hormazábal Lagos</br>\n",
    "Mohamed Aymen Merchaoui</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "## Classification problem\n",
    "\n",
    "Classify the dataset between this 10 classes.\n",
    "\n",
    "0 = Acoustic/Folk</br>\n",
    "1 = Alternative music</br>\n",
    "2 = Blues</br>\n",
    "3 = Bollywood</br>\n",
    "4 = Country</br>\n",
    "5 = Hip Hop</br>\n",
    "6 = Indie</br>\n",
    "7 = Instrumental</br>\n",
    "8 = Metal</br>\n",
    "9 = Pop</br>\n",
    "10 = Rock</br>\n",
    "\n",
    "https://www.kaggle.com/datasets/purumalgi/music-genre-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "# Imports and declarations\n",
    "\n",
    "This section contains all imports and declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb069517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\USER\\.julia\\registries\\General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ArrayInterfaceOffsetArrays ─────── v0.1.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SIMDTypes ──────────────────────── v0.1.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CpuId ──────────────────────────── v0.3.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SIMDDualNumbers ────────────────── v0.1.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ThreadingUtilities ─────────────── v0.5.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ManualMemory ───────────────────── v0.1.8\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SLEEFPirates ───────────────────── v0.6.37\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LayoutPointers ─────────────────── v0.1.12\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ArrayInterfaceStaticArraysCore ─── v0.1.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BitTwiddlingConvenienceFunctions ─ v0.1.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PolyesterWeave ─────────────────── v0.1.11\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CloseOpenIntervals ─────────────── v0.1.11\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ForceImport ────────────────────── v0.0.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LoopVectorization ──────────────── v0.12.141\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ArrayInterfaceStaticArrays ─────── v0.1.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CPUSummary ─────────────────────── v0.1.30\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HostCPUFeatures ────────────────── v0.1.13\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JLD2 ───────────────────────────── v0.4.28\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m VectorizationBase ──────────────── v0.21.56\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BetaML ─────────────────────────── v0.9.2\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\USER\\.julia\\environments\\v1.8\\Project.toml`\n",
      " \u001b[90m [024491cd] \u001b[39m\u001b[92m+ BetaML v0.9.2\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\USER\\.julia\\environments\\v1.8\\Manifest.toml`\n",
      " \u001b[90m [015c0d05] \u001b[39m\u001b[92m+ ArrayInterfaceOffsetArrays v0.1.7\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m\u001b[90m [b0d46f97] \u001b[39m\u001b[92m+ ArrayInterfaceStaticArrays v0.1.4\u001b[39m\n",
      " \u001b[90m [dd5226c6] \u001b[39m\u001b[92m+ ArrayInterfaceStaticArraysCore v0.1.3\u001b[39m\n",
      " \u001b[90m [024491cd] \u001b[39m\u001b[92m+ BetaML v0.9.2\u001b[39m\n",
      " \u001b[90m [62783981] \u001b[39m\u001b[92m+ BitTwiddlingConvenienceFunctions v0.1.5\u001b[39m\n",
      " \u001b[90m [2a0fbf3d] \u001b[39m\u001b[92m+ CPUSummary v0.1.30\u001b[39m\n",
      " \u001b[90m [fb6a15b2] \u001b[39m\u001b[92m+ CloseOpenIntervals v0.1.11\u001b[39m\n",
      " \u001b[90m [adafc99b] \u001b[39m\u001b[92m+ CpuId v0.3.1\u001b[39m\n",
      " \u001b[90m [9dda63f9] \u001b[39m\u001b[92m+ ForceImport v0.0.3\u001b[39m\n",
      " \u001b[90m [3e5b6fbb] \u001b[39m\u001b[92m+ HostCPUFeatures v0.1.13\u001b[39m\n",
      " \u001b[90m [033835bb] \u001b[39m\u001b[92m+ JLD2 v0.4.28\u001b[39m\n",
      " \u001b[90m [10f19ff3] \u001b[39m\u001b[92m+ LayoutPointers v0.1.12\u001b[39m\n",
      " \u001b[90m [bdcacae8] \u001b[39m\u001b[92m+ LoopVectorization v0.12.141\u001b[39m\n",
      " \u001b[90m [d125e4d3] \u001b[39m\u001b[92m+ ManualMemory v0.1.8\u001b[39m\n",
      " \u001b[90m [1d0040c9] \u001b[39m\u001b[92m+ PolyesterWeave v0.1.11\u001b[39m\n",
      " \u001b[90m [3cdde19b] \u001b[39m\u001b[92m+ SIMDDualNumbers v0.1.1\u001b[39m\n",
      " \u001b[90m [94e857df] \u001b[39m\u001b[92m+ SIMDTypes v0.1.0\u001b[39m\n",
      " \u001b[90m [476501e8] \u001b[39m\u001b[92m+ SLEEFPirates v0.6.37\u001b[39m\n",
      " \u001b[90m [8290d209] \u001b[39m\u001b[92m+ ThreadingUtilities v0.5.0\u001b[39m\n",
      " \u001b[90m [3d5dd08c] \u001b[39m\u001b[92m+ VectorizationBase v0.21.56\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m have new versions available and may be upgradable.\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m BetaML → `C:\\Users\\USER\\.julia\\scratchspaces\\44cfe95a-1eb2-52ea-b672-e2afdf69b78f\\cf1986b848d415400196170bf7a10a2d4fa4d261\\build.log`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSIMDTypes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mForceImport\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mManualMemory\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterfaceStaticArraysCore\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCpuId\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBitTwiddlingConvenienceFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCloseOpenIntervals\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterfaceOffsetArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mThreadingUtilities\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCPUSummary\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mHostCPUFeatures\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterfaceStaticArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPolyesterWeave\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLayoutPointers\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJLD2\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mVectorizationBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSLEEFPirates\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSIMDDualNumbers\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLoopVectorization\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mBetaML\n",
      "  20 dependencies successfully precompiled in 130 seconds. 295 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "# The next packages must be installed to run the solution\n",
    "import Pkg; \n",
    "#Pkg.add(\"Flux\")\n",
    "#Pkg.add(\"RDatasets\")\n",
    "#Pkg.add(\"FeatureSelectors\")\n",
    "#Pkg.add(\"ScikitLearn\"))\n",
    "#Pkg.add(\"WeightedPCA\"))\n",
    "# Pkg.add(\"BetaML\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20dbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Flux\n",
    "using Flux.Losses\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using Random\n",
    "using ScikitLearn\n",
    "using RDatasets\n",
    "using FeatureSelectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb0c717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.decomposition._pca.PCA'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ScikitLearn models\n",
    "@sk_import svm:SVC\n",
    "@sk_import tree:DecisionTreeClassifier\n",
    "@sk_import linear_model:LogisticRegression\n",
    "@sk_import naive_bayes:GaussianNB \n",
    "@sk_import ensemble:VotingClassifier\n",
    "@sk_import ensemble:StackingClassifier\n",
    "@sk_import ensemble:BaggingClassifier\n",
    "@sk_import decomposition:PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6167a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "# Execute model test set\n",
    "RUN_ANN_TEST = false\n",
    "RUN_SVM_TEST = false\n",
    "RUN_DT_TEST = false\n",
    "RUN_KNN_TEST = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5166c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluateModel (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include the code done in previous practices\n",
    "include(\"utils/practices_code.jl\")\n",
    "# Class that handle the data processing\n",
    "include(\"utils/data_handler.jl\")\n",
    "# Class that handle the model processing\n",
    "include(\"utils/model_handler.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bdbe7",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "This section contains the preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44543d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original size: (17997, 17)\n",
      "Sample of original dataset: Any[\"Bruno Mars\", \"That's What I Like (feat. Gucci Mane)\", 60.0, 0.854, 0.564, 1.0, -4.964, 1, 0.0485, 0.0171, \"\", 0.0849, 0.899, 134.071, 234596.0, 4, 5]\n",
      "Inputs size: (17996, 14)\n",
      "Sample of inputs: Real[60.0, 0.854, 0.564, 1.0, 4.964, 1, 0.0485, 0.0171, 0, 0.0849, 0.899, 134.071, 234596.0, 4]\n",
      "Outputs size: (17996,)\n",
      "Sample of Outputs: 5\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and normalize\n",
    "dataset = readdlm(\"dataset/music_genre.csv\",',');\n",
    "\n",
    "println(\"Dataset original size: \", size(dataset))\n",
    "println(\"Sample of original dataset: \", dataset[2,1:17])\n",
    "\n",
    "# Remove line of headers, artist and song name. Separate train_x and train_y\n",
    "train_x = dataset[2:size(dataset,1),3:16]\n",
    "train_y = dataset[2:size(dataset,1),17]\n",
    "\n",
    "# Replace all empty values for zero\n",
    "train_x = replace(train_x, \"\" => 0)\n",
    "\n",
    "# Normalize column duration in min/ms to only ms\n",
    "train_x[1:size(train_x,1),:13] = normalizeMinutesMiliseconds(train_x[1:size(train_x,1),:13])\n",
    "\n",
    "# Transform columns to positive values\n",
    "train_x = abs.(train_x)\n",
    "\n",
    "# normalized_inputs = normalizeMinMax!(train_x) --> must be after splitting\n",
    "binary_outputs = oneHotEncoding(train_y)\n",
    "\n",
    "println(\"Inputs size: \", size(train_x))\n",
    "println(\"Sample of inputs: \", train_x[1,1:14])\n",
    "println(\"Outputs size: \", size(train_y))\n",
    "println(\"Sample of Outputs: \", train_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf4bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size original input data: (17996, 14)\n",
      "Size original output data: (17996, 11)\n",
      "Size train input data: (14397, 14)\n",
      "Size train output data: (14397,)\n",
      "Size test input data: (3599, 14)\n",
      "Size test output data: (3599,)\n"
     ]
    }
   ],
   "source": [
    "# Using Hold Out function to split dataset into train, test and validation\n",
    "#indexs = holdOut(size(train_x,1),0.2,0.1)\n",
    "indexs = holdOut(size(train_x,1),0.2)\n",
    "\n",
    "train_input = train_x[indexs[1],:]\n",
    "train_output = binary_outputs[indexs[1]]\n",
    "\n",
    "test_input = train_x[indexs[2],:]\n",
    "test_output = binary_outputs[indexs[2]]\n",
    "\n",
    "#normalization after splitting, so test data cannot affect the train data and the first touch between them should be in predictions.\n",
    "train_input = normalizeMinMax!(train_input)\n",
    "test_input = normalizeMinMax!(test_input)\n",
    "\n",
    "\n",
    "#validation_input = normalized_inputs[indexs[3],:]\n",
    "#validation_output = binary_outputs[indexs[3]]\n",
    "\n",
    "println(\"Size original input data: \", size(train_x))\n",
    "println(\"Size original output data: \", size(binary_outputs))\n",
    "\n",
    "println(\"Size train input data: \", size(train_input))\n",
    "println(\"Size train output data: \", size(train_output))\n",
    "\n",
    "println(\"Size test input data: \", size(test_input))\n",
    "println(\"Size test output data: \", size(test_output))\n",
    "\n",
    "#println(\"Size validation input data: \", size(validation_input))\n",
    "#println(\"Size validation output data: \", size(validation_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd11ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Patterns (14397, 14) -> (14397, 9)Test Patterns (3599, 14) -> (3599, 9)"
     ]
    }
   ],
   "source": [
    "# applying PCA, \n",
    "pca = PCA(0.95)\n",
    "fit!(pca, train_input)\n",
    "\n",
    "pca_train = pca.transform(train_input)\n",
    "pca_test = pca.transform(test_input)\n",
    "\n",
    "print(\"Train Patterns \", size(train_input), \" -> \", size(pca_train))\n",
    "print(\"Test Patterns \", size(test_input), \" -> \", size(pca_test))\n",
    "\n",
    "# PCA based on 95% variance, suggests that there are 5 features have noise and should be eliminated\n",
    "# from the input data, it's worth to try apply it and compare, maybe after finding the optimaal\n",
    "# parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8b1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection:\n",
    "# this function can be used to the most K important features after normalization and splitting.\n",
    "# for optimal number of K, I am still searching\n",
    "#FeatureSelection(train_x,train_y,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f9e00",
   "metadata": {},
   "source": [
    "# Model experimentation\n",
    "\n",
    "This section contains all experimentation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23a05b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ANN_TEST\n",
    "    indexs = crossvalidation(train_output, 10)\n",
    "    kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "    test_ANN_Model(train_input, train_output, kFoldIndices)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "acb61da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SVM_TEST\n",
    "    indexs = crossvalidation(train_output, 10)\n",
    "    kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "    test_SVM_Model(train_input, train_output, kFoldIndices)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4be19d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_DT_TEST\n",
    "    indexs = crossvalidation(train_output, 10)\n",
    "    kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "    test_DT_Model(train_input, train_output, kFoldIndices)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77a9c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_KNN_TEST\n",
    "    indexs = crossvalidation(train_output, 10)\n",
    "    kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "    test_KNN_Model(train_input, train_output, kFoldIndices)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04b0a9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{String}:\n",
       " \"NB\"\n",
       " \"SVM\"\n",
       " \"LR\"\n",
       " \"DT\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the models to train\n",
    "\n",
    "models = Dict( \"SVM\" => SVC(probability=true), \n",
    "         \"LR\" =>LogisticRegression(),\n",
    "         \"DT\"=> DecisionTreeClassifier(max_depth=4),\n",
    "         \"NB\"=> GaussianNB())\n",
    "\n",
    "base_models =  [ name for name in keys(models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3a595d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "PyError ($(Expr(:escape, :(ccall(#= C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\pyfncall.jl:43 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'ValueError'>\nValueError('y should be a 1d array, got an array of shape (14397, 11) instead.')\n  File \"C:\\Users\\USER\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 242, in fit\n    y = self._validate_data(y=y)\n  File \"C:\\Users\\USER\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\base.py\", line 580, in _validate_data\n    y = _check_y(y, **check_params)\n  File \"C:\\Users\\USER\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1111, in _check_y\n    y = column_or_1d(y, warn=True)\n  File \"C:\\Users\\USER\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1156, in column_or_1d\n    raise ValueError(\n",
     "output_type": "error",
     "traceback": [
      "PyError ($(Expr(:escape, :(ccall(#= C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\pyfncall.jl:43 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'ValueError'>\nValueError('y should be a 1d array, got an array of shape (14397, 11) instead.')\n  File \"C:\\Users\\USER\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 242, in fit\n    y = self._validate_data(y=y)\n  File \"C:\\Users\\USER\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\base.py\", line 580, in _validate_data\n    y = _check_y(y, **check_params)\n  File \"C:\\Users\\USER\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1111, in _check_y\n    y = column_or_1d(y, warn=True)\n  File \"C:\\Users\\USER\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1156, in column_or_1d\n    raise ValueError(\n",
      "",
      "Stacktrace:",
      "  [1] pyerr_check",
      "    @ C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\exception.jl:62 [inlined]",
      "  [2] pyerr_check",
      "    @ C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\exception.jl:66 [inlined]",
      "  [3] _handle_error(msg::String)",
      "    @ PyCall C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\exception.jl:83",
      "  [4] macro expansion",
      "    @ C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\exception.jl:97 [inlined]",
      "  [5] #107",
      "    @ C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\pyfncall.jl:43 [inlined]",
      "  [6] disable_sigint",
      "    @ .\\c.jl:473 [inlined]",
      "  [7] __pycall!",
      "    @ C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\pyfncall.jl:42 [inlined]",
      "  [8] _pycall!(ret::PyCall.PyObject, o::PyCall.PyObject, args::Tuple{Matrix{Float64}, BitMatrix}, nargs::Int64, kw::Ptr{Nothing})",
      "    @ PyCall C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\pyfncall.jl:29",
      "  [9] _pycall!(ret::PyCall.PyObject, o::PyCall.PyObject, args::Tuple{Matrix{Float64}, BitMatrix}, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ PyCall C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\pyfncall.jl:11",
      " [10] (::PyCall.PyObject)(::Matrix{Float64}, ::Vararg{Any}; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ PyCall C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\pyfncall.jl:86",
      " [11] (::PyCall.PyObject)(::Matrix{Float64}, ::Vararg{Any})",
      "    @ PyCall C:\\Users\\USER\\.julia\\packages\\PyCall\\ygXW2\\src\\pyfncall.jl:86",
      " [12] fit!(::PyCall.PyObject, ::Matrix{Float64}, ::Vararg{Any}; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ ScikitLearn.Skcore C:\\Users\\USER\\.julia\\packages\\ScikitLearn\\ssekP\\src\\Skcore.jl:102",
      " [13] fit!(::PyCall.PyObject, ::Matrix{Float64}, ::BitMatrix)",
      "    @ ScikitLearn.Skcore C:\\Users\\USER\\.julia\\packages\\ScikitLearn\\ssekP\\src\\Skcore.jl:102",
      " [14] top-level scope",
      "    @ .\\In[57]:4",
      " [15] eval",
      "    @ .\\boot.jl:368 [inlined]",
      " [16] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1428"
     ]
    }
   ],
   "source": [
    "# Perform the training for each model and calculate the test values (accuracy)\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    fit!(model,train_input, train_output)\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1554b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the metaclassifier based on the base_models\n",
    "#=models[\"Ensemble (Hard Voting)\"] = VotingClassifier(estimators = [(name,models[name]) for name in base_models], \n",
    "                                                   n_jobs=-1)\n",
    "fit!(models[\"Ensemble (Hard Voting)\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "260da3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=models[\"Ensemble (Soft Voting)\"] = VotingClassifier(estimators = [(name,models[name]) for name in base_models], \n",
    "                                                   n_jobs=-1, voting=\"soft\",weights=[1,2,2,1])\n",
    "fit!(models[\"Ensemble (Soft Voting)\"],train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c70391c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=models[\"Ensemble (Stacking)\"] = StackingClassifier(estimators=[(name,models[name]) for name in base_models],\n",
    "    final_estimator=SVC(probability=true), n_jobs=-1)\n",
    "fit!(models[\"Ensemble (Stacking)\"], train_input, train_output)=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed598b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd7750d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=models[\"Bagging (SVC)\"] = BaggingClassifier(base_estimator=SVC(),n_estimators=10, max_samples=0.50, n_jobs=-1)\n",
    "fit!(models[\"Bagging (SVC)\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "830a90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=@sk_import ensemble:(AdaBoostClassifier, GradientBoostingClassifier)\n",
    "\n",
    "models[\"Ada\"] = AdaBoostClassifier(n_estimators=30)\n",
    "fit!(models[\"Ada\"], train_input, train_output)\n",
    "\n",
    "models[\"GTB\"] = GradientBoostingClassifier(n_estimators=30, learning_rate=1.0, max_depth=2, random_state=0)\n",
    "fit!(models[\"GTB\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "668be4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=@sk_import ensemble:RandomForestClassifier\n",
    "\n",
    "models[\"RF\"] = RandomForestClassifier(n_estimators=8, max_depth=nothing,\n",
    "                                    min_samples_split=2, n_jobs=-1)\n",
    "fit!(models[\"RF\"], train_input, train_output)\n",
    "    \n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea85f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=p = bar(y=1:60,models[\"RF\"].feature_importances_, orientation=:horizontal, legend = false)\n",
    "xlabel!(p,\"Gini Gain\")\n",
    "ylabel!(p,\"Fearure\")\n",
    "title!(\"Feature Importance\")=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a03972c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=using Pkg;\n",
    "Pkg.add(\"XGBoost\")=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7fd5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=using XGBoost;\n",
    "\n",
    "train_output_asNumber= Vector{Number}(train_output);\n",
    "\n",
    "@assert train_output_asNumber isa Vector{Number}=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eec905d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: incomplete: unterminated multi-line comment #= ... =#",
     "output_type": "error",
     "traceback": [
      "syntax: incomplete: unterminated multi-line comment #= ... =#",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[29]:1",
      " [2] eval",
      "   @ .\\boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1428"
     ]
    }
   ],
   "source": [
    "#=model = xgboost(train_input, 20, label = train_output_asNumber, eta = 1, max_depth = 6)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=param = [\"max_depth\" => 2,\n",
    "         \"eta\" => 1,\n",
    "         \"objective\" => \"binary:logistic\"]\n",
    "metrics = metrics = [\"error\", \"auc\"]\n",
    "model = xgboost(train_input, 20, label = train_output_asNumber, param = param, metrics = metrics)\n",
    "\n",
    "pred = predict(model, train_input)=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468354c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=using XGBoost: predict as predict_xgb\n",
    "\n",
    "pred = predict_xgb(model, test_input)\n",
    "print(\"Error of XGboost= \", sum((pred .> 0.5) .!= test_output) / float(size(pred)[1]), \"\\n\")=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e86f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=feature_gain = map(x-> (x.fname,x.gain), importance(model))\n",
    "feature, gain = first.(feature_gain), last.(feature_gain)\n",
    "\n",
    "using Plots;\n",
    "\n",
    "p = bar(gain, y=feature, orientation=\"h\", legend=false)\n",
    "xlabel!(p,\"Gain\")\n",
    "ylabel!(p,\"Feature\")\n",
    "title!(\"Feature Importance\")=#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
