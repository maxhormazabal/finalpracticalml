{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4668",
   "metadata": {},
   "source": [
    "# Machine Learning - Final assignment\n",
    "\n",
    "**Students:**\n",
    "<hr>\n",
    "Mutaz Abueisheh</br>\n",
    "Marcelo Jose Ferrer</br>\n",
    "Maximiliano Hormazábal Lagos</br>\n",
    "Mohamed Aymen Merchaoui</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "## Classification problem\n",
    "\n",
    "Classify the dataset between this 10 classes.\n",
    "\n",
    "0 = Acoustic/Folk</br>\n",
    "1 = Alternative music</br>\n",
    "2 = Blues</br>\n",
    "3 = Bollywood</br>\n",
    "4 = Country</br>\n",
    "5 = Hip Hop</br>\n",
    "6 = Indie</br>\n",
    "7 = Instrumental</br>\n",
    "8 = Metal</br>\n",
    "9 = Pop</br>\n",
    "10 = Rock</br>\n",
    "\n",
    "https://www.kaggle.com/datasets/purumalgi/music-genre-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "# Imports and declarations\n",
    "\n",
    "This section contains all imports and declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb069517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next packages must be installed to run the solution\n",
    "import Pkg; \n",
    "#Pkg.add(\"Flux\")\n",
    "#Pkg.add(\"RDatasets\")\n",
    "#Pkg.add(\"FeatureSelectors\")\n",
    "#Pkg.add(\"ScikitLearn\"))\n",
    "#Pkg.add(\"WeightedPCA\"))\n",
    "#Pkg.add(\"BetaML\")\n",
    "# Packages used To store and load models in and from disk\n",
    "# Pkg.add(\"JLD\")\n",
    "# Pkg.add(\"HDF5\")\n",
    "# Pkg.add(\"PyCallJLD\")\n",
    "# Package use to count distribution\n",
    "# Pkg.add(\"DataStructures\")\n",
    "# Pkg.add(\"MLDataPattern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20dbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Flux\n",
    "using Flux.Losses\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using Random\n",
    "using ScikitLearn\n",
    "using RDatasets\n",
    "using FeatureSelectors\n",
    "using JLD\n",
    "using PyCallJLD\n",
    "using DataStructures\n",
    "using MLDataPattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb0c717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.decomposition._pca.PCA'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ScikitLearn models\n",
    "@sk_import svm:SVC\n",
    "@sk_import tree:DecisionTreeClassifier\n",
    "@sk_import linear_model:LogisticRegression\n",
    "@sk_import neighbors: KNeighborsClassifier\n",
    "@sk_import naive_bayes:GaussianNB \n",
    "@sk_import ensemble:VotingClassifier\n",
    "@sk_import ensemble:StackingClassifier\n",
    "@sk_import ensemble:BaggingClassifier\n",
    "@sk_import decomposition:PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6167a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "# Execute model test set\n",
    "RUN_ANN_TEST = false\n",
    "RUN_SVM_TEST = false\n",
    "RUN_DT_TEST = false\n",
    "RUN_KNN_TEST = false\n",
    "ANN_FILE_PATH = \"dataset/models/ann.jld\"\n",
    "SVM_FILE_PATH = \"dataset/models/svm.jld\"\n",
    "DT_FILE_PATH = \"dataset/models/dt.jld\"\n",
    "KNN_FILE_PATH = \"dataset/models/knn.jld\"\n",
    "RERUN_TRAIN = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5166c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadModel (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include the code done in previous practices\n",
    "include(\"utils/practices_code.jl\")\n",
    "# Class that handle the data processing\n",
    "include(\"utils/data_handler.jl\")\n",
    "# Class that handle the model processing\n",
    "include(\"utils/model_handler.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bdbe7",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "This section contains the preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44543d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original size: (17924, 13)\n",
      "Sample of original dataset: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882, 5]\n",
      "17924\n",
      "13\n",
      "Inputs size: (17923, 12)\n",
      "Sample of inputs: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882]\n",
      "Sample of inputs: Any[54.0, 0.382, 0.814, 13.58626223890115, 0.0011, 0.569, 116.454, 251.733, 0, 0, 0.0406, 0.00401]\n",
      "Outputs size: (17923,)\n",
      "Sample of Outputs: 5\n",
      "Sample of Outputs: 10\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and normalize\n",
    "dataset = readdlm(\"dataset/kbest_df.csv\",',');\n",
    "\n",
    "println(\"Dataset original size: \", size(dataset))\n",
    "println(\"Sample of original dataset: \", dataset[2,:])\n",
    "\n",
    "println(size(dataset,1))\n",
    "println(size(dataset,2))\n",
    "\n",
    "# Separate train_x and train_y\n",
    "train_x = dataset[2:size(dataset,1),1:size(dataset,2)-1]\n",
    "train_y = dataset[2:size(dataset,1),size(dataset,2)]\n",
    "\n",
    "# Convert to string the classes\n",
    "train_y = string.(train_y)\n",
    "\n",
    "# normalized_inputs = normalizeMinMax!(train_x) --> must be after splitting\n",
    "# binary_outputs = oneHotEncoding(train_y) --> Done only for Ann on training\n",
    "\n",
    "println(\"Inputs size: \", size(train_x))\n",
    "println(\"Sample of inputs: \", train_x[1,:])\n",
    "println(\"Sample of inputs: \", train_x[2,:])\n",
    "println(\"Outputs size: \", size(train_y))\n",
    "println(\"Sample of Outputs: \", train_y[1])\n",
    "println(\"Sample of Outputs: \", train_y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf4bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size original input data: (17923, 12)\n",
      "Size original output data: (17923,)\n",
      "Size train input data: (12546, 12)\n",
      "Size train output data: (12546,)\n",
      "Size test input data: (5377, 12)\n",
      "Size test output data: (5377,)\n",
      "Sample original input data: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882]\n",
      "Sample train input data: [0.425531914893617, 0.40587665482725216, 0.8199963459258223, 0.7153069110103181, 0.07931726907630522, 0.6350440642820114, 0.4095655012603085, 0.12278214427098692, 0.0, 0.0, 0.056723716381418085, 4.943685786840785e-5]\n",
      "Sample test input data: [0.29896907216494845, 0.8254553339115351, 0.5820763888192906, 0.7788889689146599, 0.13353413654618473, 0.8923060992026509, 0.344533493335619, 0.10596919580502202, 0.0, 0.0, 0.1945945945945946, 0.000486846672985156]\n",
      "Unique Outputs: [\"5\", \"10\", \"6\", \"2\", \"Other\", \"8\", \"9\", \"1\"]\n"
     ]
    }
   ],
   "source": [
    "# Using Hold Out function to split dataset into train and test\n",
    "indexs = holdOut(size(train_x,1),0.3)\n",
    "\n",
    "train_input = train_x[indexs[1],:]\n",
    "train_output = vec(train_y[indexs[1],:])\n",
    "\n",
    "test_input = train_x[indexs[2],:]\n",
    "test_output = vec(train_y[indexs[2],:])\n",
    "\n",
    "#normalization after splitting, so test data cannot affect the train data and the first touch between them should be in predictions.\n",
    "train_input = normalizeMinMax!(train_input)\n",
    "test_input = normalizeMinMax!(test_input)\n",
    "\n",
    "println(\"Size original input data: \", size(train_x))\n",
    "println(\"Size original output data: \", size(train_y))\n",
    "\n",
    "println(\"Size train input data: \", size(train_input))\n",
    "println(\"Size train output data: \", size(train_output))\n",
    "\n",
    "println(\"Size test input data: \", size(test_input))\n",
    "println(\"Size test output data: \", size(test_output))\n",
    "\n",
    "println(\"Sample original input data: \", train_x[1,:])\n",
    "println(\"Sample train input data: \", train_input[1,:])\n",
    "println(\"Sample test input data: \", test_input[1,:])\n",
    "\n",
    "println(\"Unique Outputs: \", unique(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c3feb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to over or under sample. Commented because accuracy reduction\n",
    "#=println(\"Inputs size: \", size(train_input))\n",
    "println(\"Outputs size: \", size(train_output))\n",
    "\n",
    "balanced_x, balanced_y = oversample((train_input', train_output))\n",
    "balanced_x, balanced_y = undersample((train_input', train_output))\n",
    "\n",
    "println(\"Outputs Values: \", unique(train_output))\n",
    "println(\"Before balance:\", counter(train_output))\n",
    "\n",
    "train_input = getobs(balanced_x')\n",
    "train_output = getobs(balanced_y)\n",
    "\n",
    "println(\"After balance:\", counter(train_output))=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd11ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to apply Principal Component Analysis\n",
    "#=pca = PCA(0.95)\n",
    "fit!(pca, train_input)\n",
    "\n",
    "pca_train = pca.transform(train_input)\n",
    "pca_test = pca.transform(test_input)\n",
    "\n",
    "println(\"Train Patterns \", size(train_input), \" -> \", size(pca_train))\n",
    "println(\"Test Patterns \", size(test_input), \" -> \", size(pca_test))\n",
    "\n",
    "train_input = pca_train\n",
    "test_input = pca_test=#\n",
    "\n",
    "# PCA based on 95% variance, suggests that there are 5 features have noise and should be eliminated\n",
    "# from the input data, it's worth to try apply it and compare, maybe after finding the optimaal\n",
    "# parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8b1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection:\n",
    "# this function can be used to the most K important features after normalization and splitting.\n",
    "# for optimal number of K, I am still searching\n",
    "#FeatureSelection(train_x,train_y,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f9e00",
   "metadata": {},
   "source": [
    "# Model experimentation\n",
    "\n",
    "This section contains all experimentation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66278936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12546,)\n"
     ]
    }
   ],
   "source": [
    "indexs = crossvalidation(train_output, 20)\n",
    "kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "println(size(kFoldIndices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a05b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [8, 8, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.1470788072299995 Fscore: 0.06397700566782863\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [16, 12, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.14833549602502627 Fscore: 0.06655158593484004\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [32, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.14835986657979322 Fscore: 0.06685896083738449\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [16, 4, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.1473782546392911 Fscore: 0.06592014706912366\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [24, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.14619928213592642 Fscore: 0.07062468934304987\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [32, 24, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.15076690888169242 Fscore: 0.06733412838786038\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [64, 32, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.14907273001689297 Fscore: 0.06269660674379443\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [20, 16, 12, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.14846734954668533 Fscore: 0.06073894590541316\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [8, 8, 8, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.1491486403635193 Fscore: 0.060726844101933054\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.1, \"topology\" => [32, 24, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.045836412188290994 Fscore: 0.12123102852458931\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.001, \"topology\" => [32, 24, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.logσ, NNlib.logσ, NNlib.logσ, NNlib.logσ]) Accuracy: 0.14277730716185566 Fscore: 0.06768785707722581\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [32, 24, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.σ, NNlib.σ, NNlib.σ, NNlib.σ]) Accuracy: 0.1517375907273691 Fscore: 0.054205574141582225\n",
      "Parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [32, 24, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.tanh_fast, NNlib.tanh_fast, NNlib.tanh_fast, NNlib.tanh_fast]) Accuracy: 0.13936626344321165 Fscore: 0.08612052718681813\n",
      "//////////////////////////////////////////\n",
      "Best parameters: Dict{Any, Any}(\"repetitionsTraining\" => 3, \"maxEpochs\" => 500, \"learningRate\" => 0.01, \"topology\" => [32, 24, 16, 8], \"validationRatio\" => 0, \"maxEpochsVal\" => 20, \"minLoss\" => 0.0, \"transferFunctions\" => [NNlib.σ, NNlib.σ, NNlib.σ, NNlib.σ]) Best accuracy: 0.1517375907273691\n",
      "Test: Accuracy: 0.12386088897154546 Error rate: 0.8761391110284545 Sensitivity: 0.11017250894830855 Specificity rate: 0.8735904242459083 FScore: 0.04115160303810031\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: testOutputs not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: testOutputs not defined",
      "",
      "Stacktrace:",
      " [1] test_ANN_Model(train_inputs::Matrix{Float64}, train_targets::Vector{String}, test_inputs::Matrix{Float64}, test_targets::Vector{String}, kFoldIndices::Vector{Int64}, path::String)",
      "   @ Main c:\\Master\\Machine Learning Final\\finalpracticalml\\utils\\model_handler.jl:95",
      " [2] top-level scope",
      "   @ In[12]:2",
      " [3] eval",
      "   @ .\\boot.jl:368 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1428"
     ]
    }
   ],
   "source": [
    "if RUN_ANN_TEST\n",
    "    test_ANN_Model(train_input, train_output, test_input, test_output, kFoldIndices, ANN_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb61da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results for SVM model: \n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 1, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.4229176534236273 Fscore: 0.3407648984437798\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 2, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.42618836098532886 Fscore: 0.34846228068931423\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 3, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.4273044114639554 Fscore: 0.3513293481100276\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 4, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.42866403626138216 Fscore: 0.3555102890031802\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 10, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.42362989490616565 Fscore: 0.3571448061562755\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 1, \"kernel\" => \"linear\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.40450913876177486 Fscore: 0.30329593681301237\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 2, \"kernel\" => \"linear\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.4064207469195253 Fscore: 0.30888143299035364\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 10, \"kernel\" => \"linear\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.4082504352886721 Fscore: 0.31235766277250143\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 1, \"kernel\" => \"poly\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.42722200771621094 Fscore: 0.3502837101423238\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 2, \"kernel\" => \"poly\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.4265807471827305 Fscore: 0.3517549199729603\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 10, \"kernel\" => \"poly\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.4208437562982872 Fscore: 0.34752333368980515\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 1, \"kernel\" => \"sigmoid\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.24853062171565563 Fscore: 0.15164454926968876\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 2, \"kernel\" => \"sigmoid\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.23251545733787182 Fscore: 0.1464105997032253\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 10, \"kernel\" => \"sigmoid\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.22232264231425164 Fscore: 0.13619587526487303\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 4, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 5) Accuracy: 0.42866403626138216 Fscore: 0.3555102890031802\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 4, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 1) Accuracy: 0.42866403626138216 Fscore: 0.3555102890031802\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 3, \"C\" => 4, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.4236334638635859 Fscore: 0.3553975017402936\n",
      "Parameters: Dict{Any, Any}(\"tol\" => 0.01, \"kernelGamma\" => 3, \"C\" => 4, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Accuracy: 0.4234744837916925 Fscore: 0.3552637213117741\n",
      "//////////////////////////////////////////\n",
      "Best parameters: Dict{Any, Any}(\"tol\" => 0.001, \"kernelGamma\" => 2, \"C\" => 4, \"kernel\" => \"rbf\", \"shrinking\" => true, \"probability\" => false, \"coef0\" => 0.0, \"kernelDegree\" => 3) Best accuracy: 0.42866403626138216\n",
      "Test: Accuracy: 0.41807699460665804 Error rate: 0.581923005393342 Sensitivity: 0.35212615873111347 Specificity rate: 0.9089238852688694 FScore: 0.34173152091386894\n",
      "Tot: 5377 Ok: 2248 Acc: 0.418076994606658\n"
     ]
    }
   ],
   "source": [
    "if RUN_SVM_TEST\n",
    "    test_SVM_Model(train_input, train_output, test_input, test_output, kFoldIndices, SVM_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be19d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results for Decision tree model: \n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 4, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.3742877591704647 Fscore: 0.26968481003234757\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 3, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.36473533120032464 Fscore: 0.22300396003521353\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 2, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.32774655694918753 Fscore: 0.1713062660022087\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 1, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.27506838938921974 Fscore: 0.053932067243248574\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 5, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.3809828701438388 Fscore: 0.29393172492269126\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 6, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.3951719905618575 Fscore: 0.3000097701633223\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 7, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.3927868609766752 Fscore: 0.3194640953156628\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 8, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.3901532384191456 Fscore: 0.31788857748332566\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 9, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.3863226412154027 Fscore: 0.32194967482682046\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 6, \"random_state\" => 1, \"splitter\" => \"random\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Accuracy: 0.38020878528552937 Fscore: 0.2792800809033206\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 6, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 4) Accuracy: 0.3951719905618575 Fscore: 0.3000097701633223\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 6, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 3) Accuracy: 0.3951719905618575 Fscore: 0.3000097701633223\n",
      "Parameters: Dict{Any, Any}(\"max_depth\" => 6, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 5) Accuracy: 0.3951719905618575 Fscore: 0.3000097701633223\n",
      "//////////////////////////////////////////\n",
      "Best parameters: Dict{Any, Any}(\"max_depth\" => 6, \"random_state\" => 1, \"splitter\" => \"best\", \"criterion\" => \"gini\", \"min_samples_split\" => 2) Best accuracy: 0.3951719905618575\n",
      "Test: Accuracy: 0.39464385344987907 Error rate: 0.6053561465501209 Sensitivity: 0.3156085911523712 Specificity rate: 0.9047001794698204 FScore: 0.30040608471430913\n",
      "Tot: 5377 Ok: 2122 Acc: 0.3946438534498791\n"
     ]
    }
   ],
   "source": [
    "if RUN_DT_TEST\n",
    "    test_DT_Model(train_input, train_output, test_input, test_output, kFoldIndices, DT_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results for KNN model: \n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 3, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.3109185508144868 Fscore: 0.29249636917829636\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 2, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.28780936566523896 Fscore: 0.2625364079246324\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 1, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.28503276145974055 Fscore: 0.2741920229935021\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 5, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.34734598479564216 Fscore: 0.3150625765818593\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 7, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.3617033874435635 Fscore: 0.3203798143749458\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 10, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.3781196540675367 Fscore: 0.32801742145043744\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 20, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.3998901028691872 Fscore: 0.33474504492490237\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 50, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.4069766702272809 Fscore: 0.32876108832921364\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 60, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.40665578335327945 Fscore: 0.3257455747322731\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 70, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.40753029749399783 Fscore: 0.3242203421526516\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 80, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Accuracy: 0.40633490335299055 Fscore: 0.32114078962582204\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 70, \"metric\" => \"nan_euclidean\", \"weights\" => \"distance\") Accuracy: 0.37246149767618203 Fscore: 0.31171017226097086\n",
      "Parameters: Dict{Any, Any}(\"n_neighbors\" => 70, \"metric\" => \"minkowski\", \"weights\" => \"uniform\") Accuracy: 0.4074506812901803 Fscore: 0.32399370253774923\n",
      "//////////////////////////////////////////\n",
      "Best parameters: Dict{Any, Any}(\"n_neighbors\" => 70, \"metric\" => \"nan_euclidean\", \"weights\" => \"uniform\") Best accuracy: 0.40753029749399783\n",
      "Test: Accuracy: 0.4015250139482983 Sensitivity: 0.3309356602375906 Specificity rate: 0.9062901996875259 FScore: 0.31953330965772575\n",
      "Tot: 5377 Ok: 2159 Acc: 0.4015250139482983\n"
     ]
    }
   ],
   "source": [
    "if RUN_KNN_TEST\n",
    "    test_KNN_Model(train_input, train_output, test_input, test_output, kFoldIndices, KNN_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cf6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best models\n",
    "#best_ANN = loadModel(ANN_FILE_PATH)\n",
    "#if isnothing(best_ANN)\n",
    "#    best_ANN = get_Best_ANN(train_input, train_output, kFoldIndices)\n",
    "#end\n",
    "best_SVM = loadModel(SVM_FILE_PATH)\n",
    "if isnothing(best_SVM)\n",
    "    best_SVM = get_Best_SVM(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "best_DT = loadModel(DT_FILE_PATH)\n",
    "if isnothing(best_DT)\n",
    "    best_DT = get_Best_DT(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "best_KNN = loadModel(KNN_FILE_PATH)\n",
    "if isnothing(best_KNN)\n",
    "    best_KNN = get_Best_KNN(train_input, train_output, kFoldIndices)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.41807699460665804 Fscore: 0.581923005393342\n",
      "DT Accuracy: 0.39464385344987907 Fscore: 0.6053561465501209\n",
      "KNN Accuracy: 0.4015250139482983 Fscore: 0.5984749860517017\n"
     ]
    }
   ],
   "source": [
    "if RERUN_TRAIN\n",
    "    testOutputs = predict(best_SVM, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"SVM Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_DT, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"DT Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_KNN, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"KNN Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b0a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the models to train\n",
    "\n",
    "#=models = Dict( \"SVM\" => SVC(probability=true), \n",
    "         \"LR\" =>LogisticRegression(),\n",
    "         \"DT\"=> DecisionTreeClassifier(max_depth=4),\n",
    "         \"NB\"=> GaussianNB())\n",
    "\n",
    "base_models =  [ name for name in keys(models)]=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a595d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the training for each model and calculate the test values (accuracy)\n",
    "#=for key in keys(models)\n",
    "    model = models[key]\n",
    "    fit!(model,train_input, train_output)\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the metaclassifier based on the base_models\n",
    "#=models[\"Ensemble (Hard Voting)\"] = VotingClassifier(estimators = [(name,models[name]) for name in base_models], \n",
    "                                                   n_jobs=-1)\n",
    "fit!(models[\"Ensemble (Hard Voting)\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260da3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=models[\"Ensemble (Soft Voting)\"] = VotingClassifier(estimators = [(name,models[name]) for name in base_models], \n",
    "                                                   n_jobs=-1, voting=\"soft\",weights=[1,2,2,1])\n",
    "fit!(models[\"Ensemble (Soft Voting)\"],train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70391c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=models[\"Ensemble (Stacking)\"] = StackingClassifier(estimators=[(name,models[name]) for name in base_models],\n",
    "    final_estimator=SVC(probability=true), n_jobs=-1)\n",
    "fit!(models[\"Ensemble (Stacking)\"], train_input, train_output)=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed598b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7750d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=models[\"Bagging (SVC)\"] = BaggingClassifier(base_estimator=SVC(),n_estimators=10, max_samples=0.50, n_jobs=-1)\n",
    "fit!(models[\"Bagging (SVC)\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=@sk_import ensemble:(AdaBoostClassifier, GradientBoostingClassifier)\n",
    "\n",
    "models[\"Ada\"] = AdaBoostClassifier(n_estimators=30)\n",
    "fit!(models[\"Ada\"], train_input, train_output)\n",
    "\n",
    "models[\"GTB\"] = GradientBoostingClassifier(n_estimators=30, learning_rate=1.0, max_depth=2, random_state=0)\n",
    "fit!(models[\"GTB\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668be4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=@sk_import ensemble:RandomForestClassifier\n",
    "\n",
    "models[\"RF\"] = RandomForestClassifier(n_estimators=8, max_depth=nothing,\n",
    "                                    min_samples_split=2, n_jobs=-1)\n",
    "fit!(models[\"RF\"], train_input, train_output)\n",
    "    \n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=p = bar(y=1:60,models[\"RF\"].feature_importances_, orientation=:horizontal, legend = false)\n",
    "xlabel!(p,\"Gini Gain\")\n",
    "ylabel!(p,\"Fearure\")\n",
    "title!(\"Feature Importance\")=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03972c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=using Pkg;\n",
    "Pkg.add(\"XGBoost\")=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=using XGBoost;\n",
    "\n",
    "train_output_asNumber= Vector{Number}(train_output);\n",
    "\n",
    "@assert train_output_asNumber isa Vector{Number}=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec905d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = xgboost(train_input, 20, label = train_output_asNumber, eta = 1, max_depth = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=param = [\"max_depth\" => 2,\n",
    "         \"eta\" => 1,\n",
    "         \"objective\" => \"binary:logistic\"]\n",
    "metrics = metrics = [\"error\", \"auc\"]\n",
    "model = xgboost(train_input, 20, label = train_output_asNumber, param = param, metrics = metrics)\n",
    "\n",
    "pred = predict(model, train_input)=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468354c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=using XGBoost: predict as predict_xgb\n",
    "\n",
    "pred = predict_xgb(model, test_input)\n",
    "print(\"Error of XGboost= \", sum((pred .> 0.5) .!= test_output) / float(size(pred)[1]), \"\\n\")=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e86f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=feature_gain = map(x-> (x.fname,x.gain), importance(model))\n",
    "feature, gain = first.(feature_gain), last.(feature_gain)\n",
    "\n",
    "using Plots;\n",
    "\n",
    "p = bar(gain, y=feature, orientation=\"h\", legend=false)\n",
    "xlabel!(p,\"Gain\")\n",
    "ylabel!(p,\"Feature\")\n",
    "title!(\"Feature Importance\")=#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
