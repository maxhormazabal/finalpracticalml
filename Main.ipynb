{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4668",
   "metadata": {},
   "source": [
    "# Machine Learning - Final assignment\n",
    "\n",
    "**Students:**\n",
    "<hr>\n",
    "Mutaz Abueisheh</br>\n",
    "Marcelo Jose Ferrer</br>\n",
    "Maximiliano Hormazábal Lagos</br>\n",
    "Mohamed Aymen Merchaoui</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "## Classification problem\n",
    "\n",
    "Classify the dataset between this 10 classes.\n",
    "\n",
    "0 = Acoustic/Folk</br>\n",
    "1 = Alternative music</br>\n",
    "2 = Blues</br>\n",
    "3 = Bollywood</br>\n",
    "4 = Country</br>\n",
    "5 = Hip Hop</br>\n",
    "6 = Indie</br>\n",
    "7 = Instrumental</br>\n",
    "8 = Metal</br>\n",
    "9 = Pop</br>\n",
    "10 = Rock</br>\n",
    "\n",
    "https://www.kaggle.com/datasets/purumalgi/music-genre-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3b0b7",
   "metadata": {},
   "source": [
    "# Imports and declarations\n",
    "\n",
    "This section contains all imports and declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb069517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next packages must be installed to run the solution\n",
    "import Pkg; \n",
    "#Pkg.add(\"Flux\")\n",
    "#Pkg.add(\"ScikitLearn\")\n",
    "# Packages used To store and load models in and from disk\n",
    "# Pkg.add(\"JLD\")\n",
    "# Pkg.add(\"HDF5\")\n",
    "# Pkg.add(\"PyCallJLD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20dbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Flux\n",
    "using Flux.Losses\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using Random\n",
    "using ScikitLearn\n",
    "using JLD\n",
    "using PyCallJLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb0c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ScikitLearn models\n",
    "# Basic models\n",
    "@sk_import svm:SVC\n",
    "@sk_import tree:DecisionTreeClassifier\n",
    "@sk_import neural_network : MLPClassifier\n",
    "@sk_import neighbors: KNeighborsClassifier\n",
    "@sk_import naive_bayes:GaussianNB \n",
    "@sk_import linear_model:LogisticRegression\n",
    "@sk_import neighbors:NearestCentroid\n",
    "@sk_import neighbors:RadiusNeighborsClassifier\n",
    "@sk_import linear_model:RidgeClassifier\n",
    "\n",
    "# Ensemble models\n",
    "@sk_import ensemble:VotingClassifier\n",
    "@sk_import ensemble:StackingClassifier\n",
    "@sk_import ensemble:BaggingClassifier\n",
    "@sk_import ensemble: RandomForestClassifier\n",
    "@sk_import ensemble:(AdaBoostClassifier, GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5166c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadModel (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Legacy code done in previous practices\n",
    "include(\"utils/practices_code.jl\")\n",
    "# Class that handle the model processing\n",
    "include(\"utils/model_handler.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6006c",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6167a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path of the models\n",
    "ANN_FILE_PATH = \"dataset/models/ann.jld\"\n",
    "SVM_FILE_PATH = \"dataset/models/svm.jld\"\n",
    "DT_FILE_PATH = \"dataset/models/dt.jld\"\n",
    "KNN_FILE_PATH = \"dataset/models/knn.jld\"\n",
    "MLP_FILE_PATH = \"dataset/models/mlp.jld\"\n",
    "GB_FILE_PATH = \"dataset/models/gb.jld\"\n",
    "LR_FILE_PATH = \"dataset/models/lr.jld\"\n",
    "NC_FILE_PATH = \"dataset/models/nc.jld\"\n",
    "RN_FILE_PATH = \"dataset/models/rn.jld\"\n",
    "RR_FILE_PATH = \"dataset/models/rr.jld\"\n",
    "MV_FILE_PATH = \"dataset/models/mv.jld\"\n",
    "WM_FILE_PATH = \"dataset/models/wm.jld\"\n",
    "ST_FILE_PATH = \"dataset/models/st.jld\"\n",
    "BG_FILE_PATH = \"dataset/models/bg.jld\"\n",
    "BA_FILE_PATH = \"dataset/models/ba.jld\"\n",
    "GR_FILE_PATH = \"dataset/models/gr.jld\"\n",
    "RF_FILE_PATH = \"dataset/models/rf.jld\"\n",
    "# Get the metrics for the basic models\n",
    "RERUN_METRICS = true\n",
    "# Configuration to split the data\n",
    "HOLD_OUT=0.3\n",
    "NUM_FOLDS=20\n",
    "\n",
    "# Seed to make the experiment repeteables\n",
    "Random.seed!(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bdbe7",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "This section contains the preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44543d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original size: (17924, 13)\n",
      "Sample of original dataset: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882, 5]\n",
      "17924\n",
      "13\n",
      "Inputs size: (17923, 12)\n",
      "Sample of inputs: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882]\n",
      "Outputs size: (17923,)\n",
      "Sample of Outputs: 5\n",
      "Unique Outputs: [\"5\", \"10\", \"6\", \"2\", \"Other\", \"8\", \"9\", \"1\"]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from disk (already pre processed)\n",
    "dataset = readdlm(\"dataset/kbest_df.csv\",',');\n",
    "\n",
    "# Show information of the dataset\n",
    "println(\"Dataset original size: \", size(dataset))\n",
    "println(\"Sample of original dataset: \", dataset[2,:])\n",
    "\n",
    "println(size(dataset,1))\n",
    "println(size(dataset,2))\n",
    "\n",
    "# Separate the features and the output of the dataset. Remove header.\n",
    "train_x = dataset[2:size(dataset,1),1:size(dataset,2)-1]\n",
    "train_y = dataset[2:size(dataset,1),size(dataset,2)]\n",
    "\n",
    "# Convert to regular values the output classes\n",
    "train_y = string.(train_y)\n",
    "\n",
    "# Show information of the transformed dataset\n",
    "println(\"Inputs size: \", size(train_x))\n",
    "println(\"Sample of inputs: \", train_x[1,:])\n",
    "println(\"Outputs size: \", size(train_y))\n",
    "println(\"Sample of Outputs: \", train_y[1])\n",
    "println(\"Unique Outputs: \", unique(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf4bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size original input data: (17923, 12)\n",
      "Size original output data: (17923,)\n",
      "Size train input data: (12546, 12)\n",
      "Size train output data: (12546,)\n",
      "Size test input data: (5377, 12)\n",
      "Size test output data: (5377,)\n",
      "Sample original input data: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882]\n",
      "Sample train input data: [0.425531914893617, 0.40587665482725216, 0.8199963459258223, 0.7153069110103181, 0.07931726907630522, 0.6350440642820114, 0.4095655012603085, 0.12278214427098692, 0.0, 0.0, 0.056723716381418085, 4.943685786840785e-5]\n",
      "Sample test input data: [0.29896907216494845, 0.8254553339115351, 0.5820763888192906, 0.7788889689146599, 0.13353413654618473, 0.8923060992026509, 0.344533493335619, 0.10596919580502202, 0.0, 0.0, 0.1945945945945946, 0.000486846672985156]\n"
     ]
    }
   ],
   "source": [
    "# Using Hold Out function to split dataset into train and test\n",
    "indexs = holdOut(size(train_x,1),HOLD_OUT)\n",
    "\n",
    "train_input = train_x[indexs[1],:]\n",
    "train_output = vec(train_y[indexs[1],:])\n",
    "\n",
    "test_input = train_x[indexs[2],:]\n",
    "test_output = vec(train_y[indexs[2],:])\n",
    "\n",
    "#normalization after splitting, so test data cannot affect the train data and the first touch between them should be in predictions.\n",
    "train_input = normalizeMinMax!(train_input)\n",
    "test_input = normalizeMinMax!(test_input)\n",
    "\n",
    "# Show information about the splitted data\n",
    "println(\"Size original input data: \", size(train_x))\n",
    "println(\"Size original output data: \", size(train_y))\n",
    "\n",
    "println(\"Size train input data: \", size(train_input))\n",
    "println(\"Size train output data: \", size(train_output))\n",
    "\n",
    "println(\"Size test input data: \", size(test_input))\n",
    "println(\"Size test output data: \", size(test_output))\n",
    "\n",
    "println(\"Sample original input data: \", train_x[1,:])\n",
    "println(\"Sample train input data: \", train_input[1,:])\n",
    "println(\"Sample test input data: \", test_input[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66278936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12546,)\n"
     ]
    }
   ],
   "source": [
    "# Get the crossvalidation indexs for testing\n",
    "indexs = crossvalidation(train_output, NUM_FOLDS)\n",
    "kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "# Show the crossvalidation size\n",
    "println(size(kFoldIndices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f9e00",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "This section contains all training of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41cf6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LabelBinarizer from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MLPClassifier from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SVC from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator GaussianNB from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RadiusNeighborsClassifier from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get the best model for Multi-layer Perceptron\n",
    "best_MLP = loadModel(MLP_FILE_PATH)\n",
    "# If model can not be loaded from disk, reload from code\n",
    "if isnothing(best_MLP)\n",
    "    best_MLP = get_Best_MLP(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Support Vector Machine\n",
    "best_SVM = loadModel(SVM_FILE_PATH)\n",
    "if isnothing(best_SVM)\n",
    "    best_SVM = get_Best_SVM(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Decision Tree\n",
    "best_DT = loadModel(DT_FILE_PATH)\n",
    "if isnothing(best_DT)\n",
    "    best_DT = get_Best_DT(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for K-Nearest Neighbor\n",
    "best_KNN = loadModel(KNN_FILE_PATH)\n",
    "if isnothing(best_KNN)\n",
    "    best_KNN = get_Best_KNN(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Gaussian Naive Bayes\n",
    "best_GB = loadModel(GB_FILE_PATH)\n",
    "if isnothing(best_GB)\n",
    "    best_GB = get_Best_GB(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Logistic Regression\n",
    "best_LR = loadModel(LR_FILE_PATH)\n",
    "if isnothing(best_LR)\n",
    "    best_LR = get_Best_LR(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Nearest centroid\n",
    "best_NC = loadModel(NC_FILE_PATH)\n",
    "if isnothing(best_NC)\n",
    "    best_NC = get_Best_NC(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Radius Neighbors\n",
    "best_RN = loadModel(RN_FILE_PATH)\n",
    "if isnothing(best_RN)\n",
    "    best_RN = get_Best_RN(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Ridge Regression\n",
    "best_RR = loadModel(RR_FILE_PATH)\n",
    "if isnothing(best_RR)\n",
    "    best_RR = get_Best_RR(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Majority voting ensemble\n",
    "best_MV = loadModel(MV_FILE_PATH)\n",
    "if isnothing(best_MV)\n",
    "    best_MV = get_Best_MV(train_input, train_output)\n",
    "end\n",
    "# Get the best model for Weighted Majority voting ensemble\n",
    "best_WM = loadModel(WM_FILE_PATH)\n",
    "if isnothing(best_WM)\n",
    "    best_WM = get_Best_WM(train_input, train_output)\n",
    "end\n",
    "# Get the best model for Stacking ensemble\n",
    "best_ST = loadModel(ST_FILE_PATH)\n",
    "if isnothing(best_ST)\n",
    "    best_WM = get_Best_ST(train_input, train_output)\n",
    "end\n",
    "# Get the best model for Bagging ensemble\n",
    "best_BG = loadModel(BG_FILE_PATH)\n",
    "if isnothing(best_BG)\n",
    "    best_WM = get_Best_BG(train_input, train_output)\n",
    "end\n",
    "# Get the best model for boosting ADA ensemble\n",
    "best_BA = loadModel(BA_FILE_PATH)\n",
    "if isnothing(best_BA)\n",
    "    best_WM = get_Best_BA(train_input, train_output)\n",
    "end\n",
    "# Get the best model for boosting Gradient ensemble \n",
    "best_GR = loadModel(GR_FILE_PATH)\n",
    "if isnothing(best_GR)\n",
    "    best_WM = get_Best_GR(train_input, train_output)\n",
    "end\n",
    "# Get the best model for Random Forest ensemble\n",
    "best_RF = loadModel(RF_FILE_PATH)\n",
    "if isnothing(best_RF)\n",
    "    best_RF = get_Best_RF(train_input, train_output)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72b9b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron Accuracy: 0.41584526687744094 Fscore: 0.3300271949746883\n",
      "Support Vector Machine Accuracy: 0.41807699460665804 Fscore: 0.34173152091386894\n",
      "Decision Tree Accuracy: 0.39464385344987907 Fscore: 0.30040608471430913\n",
      "K-Nearest Neighbor Accuracy: 0.4015250139482983 Fscore: 0.31953330965772575\n",
      "Gaussian Naive Bayes Accuracy: 0.36470150641621724 Fscore: 0.29540609983893595\n",
      "Logistic Regression Accuracy: 0.40654640133903663 Fscore: 0.32473739612835734\n",
      "Nearest centroid Accuracy: 0.33327134089641064 Fscore: 0.28781542467962634\n",
      "Radius Neighbors Accuracy: 0.31653338292728284 Fscore: 0.12648380808891338\n",
      "Ridge Regression Accuracy: 0.39185419378835784 Fscore: 0.27596552328200097\n",
      "Majority voting ensemble: 0.4214245862004835 Fscore: 0.34381892001570125\n",
      "Weighted Majority voting ensemble: 0.42328435930816444 Fscore: 0.3483961382555924\n",
      "Stacking ensemble: 0.42105263157894735 Fscore: 0.33691450957608887\n",
      "Bagging ensemble: 0.42105263157894735 Fscore: 0.34600638688351587\n",
      "Boosting ADA ensemble: 0.3596801190254789 Fscore: 0.31893307845901303\n",
      "Boosting Gradient ensemble: 0.4128696299051515 Fscore: 0.3280385234550531\n",
      "Random Forest ensemble: 0.4301655198065836 Fscore: 0.34789622876406706\n"
     ]
    }
   ],
   "source": [
    "# Predict with the test dataset to get the metrics of each model\n",
    "if RERUN_METRICS\n",
    "    testOutputs = predict(best_MLP, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Multi-layer Perceptron Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_SVM, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Support Vector Machine Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_DT, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Decision Tree Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_KNN, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"K-Nearest Neighbor Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_GB, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Gaussian Naive Bayes Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_LR, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Logistic Regression Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_NC, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Nearest centroid Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_RN, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Radius Neighbors Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_RR, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Ridge Regression Accuracy: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "    \n",
    "    testOutputs = predict(best_MV, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Majority voting ensemble: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "\n",
    "    testOutputs = predict(best_WM, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Weighted Majority voting ensemble: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "    \n",
    "    testOutputs = predict(best_ST, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Stacking ensemble: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "    \n",
    "    testOutputs = predict(best_BG, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Bagging ensemble: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "    \n",
    "    testOutputs = predict(best_BA, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Boosting ADA ensemble: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "    \n",
    "    testOutputs = predict(best_GR, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Boosting Gradient ensemble: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "    \n",
    "    testOutputs = predict(best_RF, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Random Forest ensemble: \", metrics[1], \" Fscore: \", metrics[7])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077bb24-77b0-44f3-9dad-6afaffdf7744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
