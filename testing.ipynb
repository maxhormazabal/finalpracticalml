{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4668",
   "metadata": {},
   "source": [
    "# Model definitions and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "# Imports and declarations\n",
    "\n",
    "This section contains all imports and declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb069517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next packages must be installed to run the solution\n",
    "import Pkg; \n",
    "#Pkg.add(\"Flux\")\n",
    "#Pkg.add(\"RDatasets\")\n",
    "#Pkg.add(\"FeatureSelectors\")\n",
    "#Pkg.add(\"ScikitLearn\"))\n",
    "#Pkg.add(\"WeightedPCA\"))\n",
    "#Pkg.add(\"BetaML\")\n",
    "# Packages used To store and load models in and from disk\n",
    "# Pkg.add(\"JLD\")\n",
    "# Pkg.add(\"HDF5\")\n",
    "# Pkg.add(\"PyCallJLD\")\n",
    "# Package use to count distribution\n",
    "# Pkg.add(\"DataStructures\")\n",
    "# Pkg.add(\"MLDataPattern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20dbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Flux\n",
    "using Flux.Losses\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using Random\n",
    "using ScikitLearn\n",
    "using RDatasets\n",
    "using FeatureSelectors\n",
    "using JLD\n",
    "using PyCallJLD\n",
    "using DataStructures\n",
    "using MLDataPattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb0c717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.decomposition._pca.PCA'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ScikitLearn models\n",
    "@sk_import svm:SVC\n",
    "@sk_import tree:DecisionTreeClassifier\n",
    "@sk_import neighbors: KNeighborsClassifier\n",
    "@sk_import neural_network : MLPClassifier\n",
    "@sk_import naive_bayes:GaussianNB \n",
    "@sk_import linear_model:LogisticRegression\n",
    "@sk_import ensemble:VotingClassifier\n",
    "@sk_import ensemble:StackingClassifier\n",
    "@sk_import ensemble:BaggingClassifier\n",
    "@sk_import decomposition:PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5166c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadModel (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Legacy code done in previous practices\n",
    "include(\"utils/practices_code.jl\")\n",
    "# Class that handle the model processing\n",
    "include(\"utils/model_handler.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6167a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "# Execute model test set\n",
    "RUN_ANN_TEST = false\n",
    "RUN_SVM_TEST = false\n",
    "RUN_DT_TEST = false\n",
    "RUN_KNN_TEST = false\n",
    "RUN_MLP_TEST = false\n",
    "RUN_GB_TEST = false\n",
    "RUN_LR_TEST = false\n",
    "ANN_FILE_PATH = \"dataset/models/ann.jld\"\n",
    "ANN_DEFAULT_TRANSFER_FUNCTION=sigmoid\n",
    "SVM_FILE_PATH = \"dataset/models/svm.jld\"\n",
    "DT_FILE_PATH = \"dataset/models/dt.jld\"\n",
    "KNN_FILE_PATH = \"dataset/models/knn.jld\"\n",
    "MLP_FILE_PATH = \"dataset/models/mlp.jld\"\n",
    "GB_FILE_PATH = \"dataset/models/gb.jld\"\n",
    "LR_FILE_PATH = \"dataset/models/lr.jld\"\n",
    "UPDATE_FILE = true\n",
    "ORIGINAL_DATASET = \"dataset/music_genre.csv\"\n",
    "CLEAN_DATASET = \"dataset/clean_music_genre.csv\"\n",
    "NUMERIC_CLEAN_DATASET = \"dataset/numeric_clean_music_genre.csv\"\n",
    "KBEST_DATASET = \"dataset/kbest_df.csv\"\n",
    "CONVERT_STRING=true\n",
    "ONE_HOT_ENCODING_OUTPUT=false\n",
    "NORMALIZE_MIN_MAX=true\n",
    "USE_OVER_SAMPLE=false\n",
    "USE_UNDER_SAMPLE=false\n",
    "USE_PCA=false\n",
    "PCA_CONFIG=0.95\n",
    "HOLD_OUT=0.3\n",
    "NUM_FOLDS=20\n",
    "\n",
    "Random.seed!(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bdbe7",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "This section contains the preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44543d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original size: (17924, 13)\n",
      "Sample of original dataset: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882, 5]\n",
      "17924\n",
      "13\n",
      "Inputs size: (17923, 12)\n",
      "Sample of inputs: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882]\n",
      "Sample of inputs: Any[54.0, 0.382, 0.814, 13.58626223890115, 0.0011, 0.569, 116.454, 251.733, 0, 0, 0.0406, 0.00401]\n",
      "Outputs size: (17923,)\n",
      "Sample of Outputs: 5\n",
      "Sample of Outputs: 10\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and normalize\n",
    "dataset = readdlm(KBEST_DATASET,',');\n",
    "\n",
    "println(\"Dataset original size: \", size(dataset))\n",
    "println(\"Sample of original dataset: \", dataset[2,:])\n",
    "\n",
    "println(size(dataset,1))\n",
    "println(size(dataset,2))\n",
    "\n",
    "# Separate train_x and train_y\n",
    "train_x = dataset[2:size(dataset,1),1:size(dataset,2)-1]\n",
    "train_y = dataset[2:size(dataset,1),size(dataset,2)]\n",
    "\n",
    "# Convert to string the output classes\n",
    "if CONVERT_STRING\n",
    "    train_y = string.(train_y)\n",
    "end\n",
    "\n",
    "# Convert to one hot encoding the output classes\n",
    "if ONE_HOT_ENCODING_OUTPUT\n",
    "    train_y = oneHotEncoding(train_y)\n",
    "end\n",
    "\n",
    "println(\"Inputs size: \", size(train_x))\n",
    "println(\"Sample of inputs: \", train_x[1,:])\n",
    "println(\"Sample of inputs: \", train_x[2,:])\n",
    "println(\"Outputs size: \", size(train_y))\n",
    "println(\"Sample of Outputs: \", train_y[1])\n",
    "println(\"Sample of Outputs: \", train_y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf4bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size original input data: (17923, 12)\n",
      "Size original output data: (17923,)\n",
      "Size train input data: (12546, 12)\n",
      "Size train output data: (12546,)\n",
      "Size test input data: (5377, 12)\n",
      "Size test output data: (5377,)\n",
      "Sample original input data: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882]\n",
      "Sample train input data: [0.425531914893617, 0.40587665482725216, 0.8199963459258223, 0.7153069110103181, 0.07931726907630522, 0.6350440642820114, 0.4095655012603085, 0.12278214427098692, 0.0, 0.0, 0.056723716381418085, 4.943685786840785e-5]\n",
      "Sample test input data: [0.29896907216494845, 0.8254553339115351, 0.5820763888192906, 0.7788889689146599, 0.13353413654618473, 0.8923060992026509, 0.344533493335619, 0.10596919580502202, 0.0, 0.0, 0.1945945945945946, 0.000486846672985156]\n",
      "Unique Outputs: [\"5\", \"10\", \"6\", \"2\", \"Other\", \"8\", \"9\", \"1\"]\n"
     ]
    }
   ],
   "source": [
    "# Using Hold Out function to split dataset into train and test\n",
    "indexs = holdOut(size(train_x,1),HOLD_OUT)\n",
    "\n",
    "train_input = train_x[indexs[1],:]\n",
    "train_output = vec(train_y[indexs[1],:])\n",
    "\n",
    "test_input = train_x[indexs[2],:]\n",
    "test_output = vec(train_y[indexs[2],:])\n",
    "\n",
    "#normalization after splitting, so test data cannot affect the train data and the first touch between them should be in predictions.\n",
    "if NORMALIZE_MIN_MAX\n",
    "    train_input = normalizeMinMax!(train_input)\n",
    "    test_input = normalizeMinMax!(test_input)\n",
    "end\n",
    "\n",
    "println(\"Size original input data: \", size(train_x))\n",
    "println(\"Size original output data: \", size(train_y))\n",
    "\n",
    "println(\"Size train input data: \", size(train_input))\n",
    "println(\"Size train output data: \", size(train_output))\n",
    "\n",
    "println(\"Size test input data: \", size(test_input))\n",
    "println(\"Size test output data: \", size(test_output))\n",
    "\n",
    "println(\"Sample original input data: \", train_x[1,:])\n",
    "println(\"Sample train input data: \", train_input[1,:])\n",
    "println(\"Sample test input data: \", test_input[1,:])\n",
    "\n",
    "println(\"Unique Outputs: \", unique(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c3feb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_OVER_SAMPLE\n",
    "    println(\"Inputs size: \", size(train_input))\n",
    "    println(\"Outputs size: \", size(train_output))\n",
    "\n",
    "    balanced_x, balanced_y = oversample((train_input', train_output))\n",
    "\n",
    "    println(\"Outputs Values: \", unique(train_output))\n",
    "    println(\"Before balance:\", counter(train_output))\n",
    "\n",
    "    train_input = getobs(balanced_x')\n",
    "    train_output = getobs(balanced_y)\n",
    "\n",
    "    println(\"After balance:\", counter(train_output))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4335aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_UNDER_SAMPLE\n",
    "    println(\"Inputs size: \", size(train_input))\n",
    "    println(\"Outputs size: \", size(train_output))\n",
    "\n",
    "    balanced_x, balanced_y = undersample((train_input', train_output))\n",
    "\n",
    "    println(\"Outputs Values: \", unique(train_output))\n",
    "    println(\"Before balance:\", counter(train_output))\n",
    "\n",
    "    train_input = getobs(balanced_x')\n",
    "    train_output = getobs(balanced_y)\n",
    "\n",
    "    println(\"After balance:\", counter(train_output))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd11ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Principal Component Analysis\n",
    "if USE_PCA\n",
    "    pca = PCA(PCA_CONFIG)\n",
    "    fit!(pca, train_input)\n",
    "\n",
    "    pca_train = pca.transform(train_input)\n",
    "    pca_test = pca.transform(test_input)\n",
    "\n",
    "    println(\"Train Patterns \", size(train_input), \" -> \", size(pca_train))\n",
    "    println(\"Test Patterns \", size(test_input), \" -> \", size(pca_test))\n",
    "\n",
    "    train_input = pca_train\n",
    "    test_input = pca_test\n",
    "\n",
    "    # PCA based on 95% variance, suggests that there are 5 features have noise and should be eliminated\n",
    "    # from the input data, it's worth to try apply it and compare, maybe after finding the optimaal\n",
    "    # parameters of the model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66278936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12546,)\n"
     ]
    }
   ],
   "source": [
    "indexs = crossvalidation(train_output, NUM_FOLDS)\n",
    "kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "println(size(kFoldIndices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f9e00",
   "metadata": {},
   "source": [
    "# Model experimentation\n",
    "\n",
    "This section contains all experimentation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a05b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ANN_TEST\n",
    "    test_ANN_Model(train_input, train_output, test_input, test_output, kFoldIndices, ANN_DEFAULT_TRANSFER_FUNCTION, UPDATE_FILE, ANN_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb61da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SVM_TEST\n",
    "    test_SVM_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, SVM_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be19d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_DT_TEST\n",
    "    test_DT_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, DT_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a9c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_KNN_TEST\n",
    "    test_KNN_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, KNN_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b68b0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MLP_TEST\n",
    "    test_MLP_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, MLP_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "729c7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GB_TEST\n",
    "    test_GB_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, GB_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b006ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results for LR model: \n",
      "Parameters: Dict{Any, Any}(\"max_iter\" => 1000) Accuracy: 0.4066647970835507 Fscore: 0.3261618555880831\n",
      "Parameters: Dict{Any, Any}(\"max_iter\" => 2000) Accuracy: 0.4066647970835507 Fscore: 0.3261618555880831\n",
      "Parameters: Dict{Any, Any}(\"max_iter\" => 800) Accuracy: 0.4066647970835507 Fscore: 0.3261618555880831\n",
      "Parameters: Dict{Any, Any}(\"max_iter\" => 500) Accuracy: 0.4066647970835507 Fscore: 0.3261618555880831\n",
      "//////////////////////////////////////////\n",
      "Best parameters: Dict{Any, Any}(\"max_iter\" => 1000) Best accuracy: 0.4066647970835507\n",
      "Test: Accuracy: 0.40654640133903663 Sensitivity: 0.34275728535898115 Specificity rate: 0.9071324615350144 FScore: 0.32473739612835734\n",
      "Tot: 5377 Ok: 2186 Acc: 0.40654640133903663\n"
     ]
    }
   ],
   "source": [
    "if RUN_LR_TEST\n",
    "    test_LR_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, LR_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21f2b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar plot de los test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c56be0",
   "metadata": {},
   "source": [
    "Agregar grilla con todas las pruebas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
