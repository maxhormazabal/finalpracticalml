{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4668",
   "metadata": {},
   "source": [
    "# Model definitions and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "# Imports and declarations\n",
    "\n",
    "This section contains all imports and declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb069517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next packages must be installed to run the solution\n",
    "import Pkg; \n",
    "#Pkg.add(\"Flux\")\n",
    "#Pkg.add(\"RDatasets\")\n",
    "#Pkg.add(\"FeatureSelectors\")\n",
    "#Pkg.add(\"ScikitLearn\")\n",
    "#Pkg.add(\"WeightedPCA\")\n",
    "#Pkg.add(\"BetaML\")\n",
    "# Packages used To store and load models in and from disk\n",
    "#Pkg.add(\"JLD\")\n",
    "#Pkg.add(\"HDF5\")\n",
    "#Pkg.add(\"PyCallJLD\")\n",
    "# Package use to count distribution\n",
    "#Pkg.add(\"DataStructures\")\n",
    "#Pkg.add(\"MLDataPattern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20dbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Flux\n",
    "using Flux.Losses\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using Random\n",
    "using ScikitLearn\n",
    "using RDatasets\n",
    "using FeatureSelectors\n",
    "using JLD\n",
    "using PyCallJLD\n",
    "using DataStructures\n",
    "using MLDataPattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb0c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.decomposition._pca.PCA'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ScikitLearn models\n",
    "# Basic models\n",
    "@sk_import svm:SVC\n",
    "@sk_import tree:DecisionTreeClassifier\n",
    "@sk_import neighbors:KNeighborsClassifier\n",
    "@sk_import neural_network:MLPClassifier\n",
    "@sk_import naive_bayes:GaussianNB \n",
    "@sk_import linear_model:LogisticRegression\n",
    "@sk_import neighbors:NearestCentroid\n",
    "@sk_import neighbors:RadiusNeighborsClassifier\n",
    "@sk_import linear_model:RidgeClassifier\n",
    "\n",
    "# Ensemble models\n",
    "@sk_import ensemble:VotingClassifier\n",
    "@sk_import ensemble:StackingClassifier\n",
    "@sk_import ensemble:BaggingClassifier\n",
    "@sk_import ensemble: RandomForestClassifier\n",
    "@sk_import ensemble:(AdaBoostClassifier, GradientBoostingClassifier)\n",
    "\n",
    "@sk_import decomposition:PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5166c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadModel (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Legacy code done in previous practices\n",
    "include(\"utils/practices_code.jl\")\n",
    "# Class that handle the model processing\n",
    "include(\"utils/model_handler.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6167a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "# Execute model test set\n",
    "RUN_ANN_TEST = false\n",
    "RUN_SVM_TEST = false\n",
    "RUN_DT_TEST = false\n",
    "RUN_KNN_TEST = false\n",
    "RUN_MLP_TEST = false\n",
    "RUN_GB_TEST = false\n",
    "RUN_LR_TEST = false\n",
    "RUN_NC_TEST = false\n",
    "RUN_RN_TEST = false\n",
    "RUN_RR_TEST = false\n",
    "RUN_MV_TEST = false\n",
    "RUN_WM_TEST = false\n",
    "RUN_ST_TEST = false\n",
    "RUN_BG_TEST = false\n",
    "RUN_BA_TEST = false\n",
    "RUN_GR_TEST = false\n",
    "RUN_RF_TEST = true\n",
    "# Path of the models\n",
    "ANN_FILE_PATH = \"dataset/models/ann.jld\"\n",
    "SVM_FILE_PATH = \"dataset/models/svm.jld\"\n",
    "DT_FILE_PATH = \"dataset/models/dt.jld\"\n",
    "KNN_FILE_PATH = \"dataset/models/knn.jld\"\n",
    "MLP_FILE_PATH = \"dataset/models/mlp.jld\"\n",
    "GB_FILE_PATH = \"dataset/models/gb.jld\"\n",
    "LR_FILE_PATH = \"dataset/models/lr.jld\"\n",
    "NC_FILE_PATH = \"dataset/models/nc.jld\"\n",
    "RN_FILE_PATH = \"dataset/models/rn.jld\"\n",
    "RR_FILE_PATH = \"dataset/models/rr.jld\"\n",
    "MV_FILE_PATH = \"dataset/models/mv.jld\"\n",
    "WM_FILE_PATH = \"dataset/models/wm.jld\"\n",
    "ST_FILE_PATH = \"dataset/models/st.jld\"\n",
    "BG_FILE_PATH = \"dataset/models/bg.jld\"\n",
    "BA_FILE_PATH = \"dataset/models/ba.jld\"\n",
    "GR_FILE_PATH = \"dataset/models/gr.jld\"\n",
    "RF_FILE_PATH = \"dataset/models/rf.jld\"\n",
    "# Reload the best models from disk\n",
    "RELOAD_MODELS = true\n",
    "# Default transfer function for the ANN\n",
    "ANN_DEFAULT_TRANSFER_FUNCTION=sigmoid\n",
    "# Overwrite model in file\n",
    "UPDATE_FILE = true\n",
    "# Possible datasets to test\n",
    "ORIGINAL_DATASET = \"dataset/music_genre.csv\"\n",
    "CLEAN_DATASET = \"dataset/clean_music_genre.csv\"\n",
    "NUMERIC_CLEAN_DATASET = \"dataset/numeric_clean_music_genre.csv\"\n",
    "KBEST_DATASET = \"dataset/kbest_df.csv\"\n",
    "# Which type of output to test\n",
    "REGULAR_OUTPUT=true\n",
    "ONE_HOT_ENCODING_OUTPUT=false\n",
    "# Normalize values with min and max\n",
    "NORMALIZE_MIN_MAX=true\n",
    "# Use different types of samples\n",
    "USE_OVER_SAMPLE=false\n",
    "USE_UNDER_SAMPLE=false\n",
    "USE_PCA=false\n",
    "PCA_CONFIG=0.95\n",
    "# Configuration to split the data for testing\n",
    "HOLD_OUT=0.3\n",
    "# Number of folds to use in crossvalidation\n",
    "NUM_FOLDS=20\n",
    "\n",
    "# Seed to make the experiment repeteables\n",
    "Random.seed!(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bdbe7",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "This section contains the preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44543d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original size: (17924, 13)\n",
      "Sample of original dataset: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882, 5]\n",
      "17924\n",
      "13\n",
      "Inputs size: (17923, 12)\n",
      "Sample of inputs: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882]\n",
      "Outputs size: (17923,)\n",
      "Unique Outputs: [\"5\", \"10\", \"6\", \"2\", \"Other\", \"8\", \"9\", \"1\"]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from disk (already pre processed)\n",
    "dataset = readdlm(KBEST_DATASET,',');\n",
    "\n",
    "# Show information of the dataset\n",
    "println(\"Dataset original size: \", size(dataset))\n",
    "println(\"Sample of original dataset: \", dataset[2,:])\n",
    "println(size(dataset,1))\n",
    "println(size(dataset,2))\n",
    "\n",
    "# Separate the features and the output of the dataset. Remove header.\n",
    "train_x = dataset[2:size(dataset,1),1:size(dataset,2)-1]\n",
    "train_y = dataset[2:size(dataset,1),size(dataset,2)]\n",
    "\n",
    "# Convert to regular values the output classes\n",
    "if REGULAR_OUTPUT\n",
    "    train_y = string.(train_y)\n",
    "end\n",
    "\n",
    "# Convert to one hot encoding the output classes\n",
    "if ONE_HOT_ENCODING_OUTPUT\n",
    "    train_y = oneHotEncoding(train_y)\n",
    "end\n",
    "\n",
    "\n",
    "# Show information of the transformed dataset\n",
    "println(\"Inputs size: \", size(train_x))\n",
    "println(\"Sample of inputs: \", train_x[1,:])\n",
    "println(\"Outputs size: \", size(train_y))\n",
    "println(\"Unique Outputs: \", unique(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf4bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size original input data: (17923, 12)\n",
      "Size original output data: (17923,)\n",
      "Size train input data: (12546, 12)\n",
      "Size train output data: (12546,)\n",
      "Size test input data: (5377, 12)\n",
      "Size test output data: (5377,)\n",
      "Sample original input data: Any[52.2, 0.854, 0.564, 12.18585911937475, 0.0171, 0.899, 134.071, 234.596, 1, 0, 0.03404, 0.00965882]\n",
      "Sample train input data: [0.425531914893617, 0.40587665482725216, 0.8199963459258223, 0.7153069110103181, 0.07931726907630522, 0.6350440642820114, 0.4095655012603085, 0.12278214427098692, 0.0, 0.0, 0.056723716381418085, 4.943685786840785e-5]\n",
      "Sample test input data: [0.29896907216494845, 0.8254553339115351, 0.5820763888192906, 0.7788889689146599, 0.13353413654618473, 0.8923060992026509, 0.344533493335619, 0.10596919580502202, 0.0, 0.0, 0.1945945945945946, 0.000486846672985156]\n"
     ]
    }
   ],
   "source": [
    "# Using Hold Out function to split dataset into train and test\n",
    "indexs = holdOut(size(train_x,1),HOLD_OUT)\n",
    "\n",
    "train_input = train_x[indexs[1],:]\n",
    "train_output = vec(train_y[indexs[1],:])\n",
    "\n",
    "test_input = train_x[indexs[2],:]\n",
    "test_output = vec(train_y[indexs[2],:])\n",
    "\n",
    "#normalization after splitting, so test data cannot affect the train data and the first touch between them should be in predictions.\n",
    "if NORMALIZE_MIN_MAX\n",
    "    train_input = normalizeMinMax!(train_input)\n",
    "    test_input = normalizeMinMax!(test_input)\n",
    "end\n",
    "\n",
    "# Show information about the splitted data\n",
    "println(\"Size original input data: \", size(train_x))\n",
    "println(\"Size original output data: \", size(train_y))\n",
    "\n",
    "println(\"Size train input data: \", size(train_input))\n",
    "println(\"Size train output data: \", size(train_output))\n",
    "\n",
    "println(\"Size test input data: \", size(test_input))\n",
    "println(\"Size test output data: \", size(test_output))\n",
    "\n",
    "println(\"Sample original input data: \", train_x[1,:])\n",
    "println(\"Sample train input data: \", train_input[1,:])\n",
    "println(\"Sample test input data: \", test_input[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c3feb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the over sample option is active\n",
    "if USE_OVER_SAMPLE\n",
    "    # Show inputs before aplying over sample\n",
    "    println(\"Inputs size: \", size(train_input))\n",
    "    println(\"Outputs size: \", size(train_output))\n",
    "\n",
    "    # Balance the dataset\n",
    "    balanced_x, balanced_y = oversample((train_input', train_output))\n",
    "\n",
    "    # Show previous values\n",
    "    println(\"Outputs Values: \", unique(train_output))\n",
    "    println(\"Before balance:\", counter(train_output))\n",
    "\n",
    "    # Get and show over sampled dataset\n",
    "    train_input = getobs(balanced_x')\n",
    "    train_output = getobs(balanced_y)\n",
    "\n",
    "    println(\"After balance:\", counter(train_output))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4335aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the under sample option is active\n",
    "if USE_UNDER_SAMPLE\n",
    "    # Show inputs before aplying under sample\n",
    "    println(\"Inputs size: \", size(train_input))\n",
    "    println(\"Outputs size: \", size(train_output))\n",
    "\n",
    "    # Balance the dataset\n",
    "    balanced_x, balanced_y = undersample((train_input', train_output))\n",
    "\n",
    "    # Show previous values\n",
    "    println(\"Outputs Values: \", unique(train_output))\n",
    "    println(\"Before balance:\", counter(train_output))\n",
    "\n",
    "    # Get and show under sampled dataset\n",
    "    train_input = getobs(balanced_x')\n",
    "    train_output = getobs(balanced_y)\n",
    "\n",
    "    println(\"After balance:\", counter(train_output))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd11ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Principal Component Analysis\n",
    "if USE_PCA\n",
    "    # PCA based on 95% variance, suggests that there are 5 features have noise and should be eliminated\n",
    "    # Load the PCA configuration\n",
    "    pca = PCA(PCA_CONFIG)\n",
    "\n",
    "    # Fit the input dataset with the configuration\n",
    "    fit!(pca, train_input)\n",
    "\n",
    "    # Transform the dataset with the new features\n",
    "    pca_train = pca.transform(train_input)\n",
    "    pca_test = pca.transform(test_input)\n",
    "\n",
    "    # Show the difference after applying PCA\n",
    "    println(\"Train Patterns \", size(train_input), \" -> \", size(pca_train))\n",
    "    println(\"Test Patterns \", size(test_input), \" -> \", size(pca_test))\n",
    "\n",
    "    # Assing the PCA dataset to the testing\n",
    "    train_input = pca_train\n",
    "    test_input = pca_test\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66278936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12546,)\n"
     ]
    }
   ],
   "source": [
    "# Get the crossvalidation indexs for testing\n",
    "indexs = crossvalidation(train_output, NUM_FOLDS)\n",
    "kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "# Show the crossvalidation size\n",
    "println(size(kFoldIndices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f9e00",
   "metadata": {},
   "source": [
    "# Model experimentation\n",
    "\n",
    "This section contains all experimentation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a05b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Artificial Neural Network model\n",
    "if RUN_ANN_TEST\n",
    "    test_ANN_Model(train_input, train_output, test_input, test_output, kFoldIndices, ANN_DEFAULT_TRANSFER_FUNCTION, UPDATE_FILE, ANN_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb61da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Support Vector Machine model\n",
    "if RUN_SVM_TEST\n",
    "    test_SVM_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, SVM_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be19d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Decision Tree model\n",
    "if RUN_DT_TEST\n",
    "    test_DT_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, DT_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a9c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for K-Nearest Neighbor model\n",
    "if RUN_KNN_TEST\n",
    "    test_KNN_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, KNN_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b68b0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Multi-layer Perceptron model\n",
    "if RUN_MLP_TEST\n",
    "    test_MLP_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, MLP_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "729c7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Gaussian Naive Bayes model\n",
    "if RUN_GB_TEST\n",
    "    test_GB_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, GB_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b006ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Logistic Regression model\n",
    "if RUN_LR_TEST\n",
    "    test_LR_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, LR_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70c44313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Nearest centroid model\n",
    "if RUN_NC_TEST\n",
    "    test_NC_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, NC_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5adf4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Radius Neighbors model\n",
    "if RUN_RN_TEST\n",
    "    test_RN_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, RN_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c94c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test case for Ridge Regression model\n",
    "if RUN_RR_TEST\n",
    "    test_RR_Model(train_input, train_output, test_input, test_output, kFoldIndices, UPDATE_FILE, RR_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "215c96a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LabelBinarizer from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MLPClassifier from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SVC from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator GaussianNB from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RadiusNeighborsClassifier from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if RELOAD_MODELS\n",
    "    # Get the best model for Multi-layer Perceptron\n",
    "    best_MLP = loadModel(MLP_FILE_PATH)\n",
    "    # If model can not be loaded from disk, reload from code\n",
    "    if isnothing(best_MLP)\n",
    "        best_MLP = get_Best_MLP(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "    # Get the best model for Support Vector Machine\n",
    "    best_SVM = loadModel(SVM_FILE_PATH)\n",
    "    if isnothing(best_SVM)\n",
    "        best_SVM = get_Best_SVM(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "    # Get the best model for Decision Tree\n",
    "    best_DT = loadModel(DT_FILE_PATH)\n",
    "    if isnothing(best_DT)\n",
    "        best_DT = get_Best_DT(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "    # Get the best model for K-Nearest Neighbor\n",
    "    best_KNN = loadModel(KNN_FILE_PATH)\n",
    "    if isnothing(best_KNN)\n",
    "        best_KNN = get_Best_KNN(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "    # Get the best model for Gaussian Naive Bayes\n",
    "    best_GB = loadModel(GB_FILE_PATH)\n",
    "    if isnothing(best_GB)\n",
    "        best_GB = get_Best_GB(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "    # Get the best model for Logistic Regression\n",
    "    best_LR = loadModel(LR_FILE_PATH)\n",
    "    if isnothing(best_LR)\n",
    "        best_LR = get_Best_LR(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "    # Get the best model for Nearest centroid\n",
    "    best_NC = loadModel(NC_FILE_PATH)\n",
    "    if isnothing(best_NC)\n",
    "        best_NC = get_Best_NC(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "    # Get the best model for Radius Neighbors\n",
    "    best_RN = loadModel(RN_FILE_PATH)\n",
    "    if isnothing(best_RN)\n",
    "        best_RN = get_Best_RN(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "    # Get the best model for Ridge Regression\n",
    "    best_RR = loadModel(RR_FILE_PATH)\n",
    "    if isnothing(best_RR)\n",
    "        best_RR = get_Best_RR(train_input, train_output, kFoldIndices)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0efd64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MV_TEST\n",
    "    models = Dict(\"SVM\" => best_SVM,\n",
    "              \"DT\"=> best_DT,\n",
    "              \"KNN\"=> best_KNN,\n",
    "              \"MLP\"=> best_MLP,\n",
    "              \"LR\"=> best_LR,\n",
    "              \"RR\"=> best_RR)\n",
    "\n",
    "    test_MV_Model(train_input, train_output, test_input, test_output, models, UPDATE_FILE, MV_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4864c5fb-dc92-4870-9cf8-24ce626ee11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_WM_TEST\n",
    "    models = Dict(\"SVM\" => best_SVM,\n",
    "              \"DT\"=> best_DT,\n",
    "              \"KNN\"=> best_KNN,\n",
    "              \"MLP\"=> best_MLP,\n",
    "              \"LR\"=> best_LR,\n",
    "              \"RR\"=> best_RR)\n",
    "\n",
    "    test_WM_Model(train_input, train_output, test_input, test_output, models, UPDATE_FILE, WM_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eca1338-04ed-4946-a18b-c83ffe3f1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ST_TEST\n",
    "    models = Dict(\"SVM\" => best_SVM,\n",
    "              \"DT\"=> best_DT,\n",
    "              \"KNN\"=> best_KNN,\n",
    "              \"MLP\"=> best_MLP,\n",
    "              \"LR\"=> best_LR,\n",
    "              \"RR\"=> best_RR)\n",
    "\n",
    "    test_ST_Model(train_input, train_output, test_input, test_output, models, UPDATE_FILE, ST_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "054be4e4-0185-4058-ab84-ba5aaeb1c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_BG_TEST\n",
    "    models = Dict(\"SVM\" => best_SVM,\n",
    "              \"DT\"=> best_DT,\n",
    "              \"KNN\"=> best_KNN,\n",
    "              \"MLP\"=> best_MLP,\n",
    "              \"LR\"=> best_LR,\n",
    "              \"RR\"=> best_RR)\n",
    "\n",
    "    test_BG_Model(train_input, train_output, test_input, test_output, models, UPDATE_FILE, BG_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e95a5e95-9a82-466e-b46b-146f3e20404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_BA_TEST\n",
    "    models = Dict(\"SVM\" => best_SVM,\n",
    "              \"DT\"=> best_DT,\n",
    "              \"KNN\"=> best_KNN,\n",
    "              \"MLP\"=> best_MLP,\n",
    "              \"LR\"=> best_LR,\n",
    "              \"RR\"=> best_RR)\n",
    "\n",
    "    test_BA_Model(train_input, train_output, test_input, test_output, models, UPDATE_FILE, BA_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7eaf706-1c7d-4d5c-98b9-fa86cfb3662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GR_TEST\n",
    "    test_GR_Model(train_input, train_output, test_input, test_output, UPDATE_FILE, GR_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6625c515-48c9-451c-9992-788fdf9df367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Dict{String, Any}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"max_depth\" => 2, \"n_estimators\" => 50, \"max_features\" => \"auto\") Accuracy: 0.33940859215175745 Fscore: 0.17662558538231618\n",
      "Parameters: Dict{String, Any}(\"max_depth\" => 10, \"n_estimators\" => 50, \"max_features\" => \"auto\") Accuracy: 0.41789101729588995 Fscore: 0.3337338958051272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Dict{String, Any}(\"max_depth\" => 20, \"n_estimators\" => 50, \"max_features\" => \"auto\") Accuracy: 0.3998512181513856 Fscore: 0.34503072347116787\n",
      "Parameters: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{String, Any}(\"max_depth\" => 11, \"n_estimators\" => 180, \"max_features\" => \"auto\") Accuracy: 0.4257020643481495 Fscore: 0.3429817405972761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Dict{String, Any}(\"max_depth\" => 2, \"n_estimators\" => 50, \"max_features\" => \"sqrt\") Accuracy: 0.33513111400409146 Fscore: 0.15227364875200558\n",
      "Parameters: Dict{String, Any}(\"max_depth\" => 10, \"n_estimators\" => 50, \"max_features\" => \"sqrt\") Accuracy: 0.42607401896968566 Fscore: 0.3401550126090246\n",
      "Parameters: Dict{String, Any}(\"max_depth\" => 20, \"n_estimators\" => 50, \"max_features\" => \"sqrt\") Accuracy: 0.40115305932676215 Fscore: 0.3501602621637918\n",
      "Parameters: Dict{String, Any}(\"max_depth\" => 11, \"n_estimators\" => 180, \"max_features\" => \"sqrt\") Accuracy: 0.424586200483541 Fscore: 0.3411252348936497\n",
      "//////////////////////////////////////////\n",
      "Best parameters: PyObject RandomForestClassifier(max_depth=11, n_estimators=180)\n",
      "Test: Accuracy: 0.4301655198065836 Sensitivity: 0.36076204140128754 Specificity rate: 0.9103528918212519 FScore: 0.34789622876406706\n",
      "Tot: 5377 Ok: 2313 Acc: 0.4301655198065836\n"
     ]
    }
   ],
   "source": [
    "if RUN_RF_TEST\n",
    "    test_RF_Model(train_input, train_output, test_input, test_output, UPDATE_FILE, RF_FILE_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca21d7-1d89-4cfe-8ba0-f9556dc25ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
