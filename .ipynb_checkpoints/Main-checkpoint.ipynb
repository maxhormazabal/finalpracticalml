{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4668",
   "metadata": {},
   "source": [
    "# Machine Learning - Final assignment\n",
    "\n",
    "**Students:**\n",
    "<hr>\n",
    "Mutaz Abueisheh</br>\n",
    "Marcelo Jose Ferrer</br>\n",
    "Maximiliano Hormazábal Lagos</br>\n",
    "Mohamed Aymen Merchaoui</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "## Classification problem\n",
    "\n",
    "Classify the dataset between this 10 classes.\n",
    "\n",
    "0 = Acoustic/Folk</br>\n",
    "1 = Alternative music</br>\n",
    "2 = Blues</br>\n",
    "3 = Bollywood</br>\n",
    "4 = Country</br>\n",
    "5 = Hip Hop</br>\n",
    "6 = Indie</br>\n",
    "7 = Instrumental</br>\n",
    "8 = Metal</br>\n",
    "9 = Pop</br>\n",
    "10 = Rock</br>\n",
    "\n",
    "https://www.kaggle.com/datasets/purumalgi/music-genre-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3b0b7",
   "metadata": {},
   "source": [
    "# Imports and declarations\n",
    "\n",
    "This section contains all imports and declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb069517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next packages must be installed to run the solution\n",
    "import Pkg; \n",
    "#Pkg.add(\"Flux\")\n",
    "#Pkg.add(\"ScikitLearn\")\n",
    "# Packages used To store and load models in and from disk\n",
    "# Pkg.add(\"JLD\")\n",
    "# Pkg.add(\"HDF5\")\n",
    "# Pkg.add(\"PyCallJLD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20dbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Flux\n",
    "using Flux.Losses\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using Random\n",
    "using ScikitLearn\n",
    "using JLD\n",
    "using PyCallJLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb0c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<11.4'` in root environment\n",
      "└ @ Conda /root/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... "
     ]
    }
   ],
   "source": [
    "# Import ScikitLearn models\n",
    "# Basic models\n",
    "@sk_import svm:SVC\n",
    "@sk_import tree:DecisionTreeClassifier\n",
    "@sk_import neural_network : MLPClassifier\n",
    "@sk_import neighbors: KNeighborsClassifier\n",
    "@sk_import naive_bayes:GaussianNB \n",
    "@sk_import linear_model:LogisticRegression\n",
    "@sk_import neighbors:NearestCentroid\n",
    "@sk_import neighbors:RadiusNeighborsClassifier\n",
    "@sk_import linear_model:RidgeClassifier\n",
    "\n",
    "# Ensemble models\n",
    "@sk_import ensemble:VotingClassifier\n",
    "@sk_import ensemble:StackingClassifier\n",
    "@sk_import ensemble:BaggingClassifier\n",
    "@sk_import ensemble: RandomForestClassifier\n",
    "@sk_import ensemble:(AdaBoostClassifier, GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5166c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy code done in previous practices\n",
    "include(\"utils/practices_code.jl\")\n",
    "# Class that handle the model processing\n",
    "include(\"utils/model_handler.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6006c",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6167a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the models\n",
    "ANN_FILE_PATH = \"dataset/models/ann.jld\"\n",
    "SVM_FILE_PATH = \"dataset/models/svm.jld\"\n",
    "DT_FILE_PATH = \"dataset/models/dt.jld\"\n",
    "KNN_FILE_PATH = \"dataset/models/knn.jld\"\n",
    "MLP_FILE_PATH = \"dataset/models/mlp.jld\"\n",
    "GB_FILE_PATH = \"dataset/models/gb.jld\"\n",
    "LR_FILE_PATH = \"dataset/models/lr.jld\"\n",
    "NC_FILE_PATH = \"dataset/models/nc.jld\"\n",
    "RN_FILE_PATH = \"dataset/models/rn.jld\"\n",
    "RR_FILE_PATH = \"dataset/models/rr.jld\"\n",
    "MV_FILE_PATH = \"dataset/models/mv.jld\"\n",
    "WM_FILE_PATH = \"dataset/models/wm.jld\"\n",
    "ST_FILE_PATH = \"dataset/models/st.jld\"\n",
    "BG_FILE_PATH = \"dataset/models/bg.jld\"\n",
    "BA_FILE_PATH = \"dataset/models/ba.jld\"\n",
    "GR_FILE_PATH = \"dataset/models/gr.jld\"\n",
    "RF_FILE_PATH = \"dataset/models/rf.jld\"\n",
    "# Get the metrics for the basic models\n",
    "RERUN_METRICS = true\n",
    "# Configuration to split the data\n",
    "HOLD_OUT=0.3\n",
    "NUM_FOLDS=20\n",
    "\n",
    "# Seed to make the experiment repeteables\n",
    "Random.seed!(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bdbe7",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "This section contains the preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44543d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from disk (already pre processed)\n",
    "dataset = readdlm(\"dataset/kbest_df.csv\",',');\n",
    "\n",
    "# Show information of the dataset\n",
    "println(\"Dataset original size: \", size(dataset))\n",
    "println(\"Sample of original dataset: \", dataset[2,:])\n",
    "\n",
    "println(size(dataset,1))\n",
    "println(size(dataset,2))\n",
    "\n",
    "# Separate the features and the output of the dataset. Remove header.\n",
    "train_x = dataset[2:size(dataset,1),1:size(dataset,2)-1]\n",
    "train_y = dataset[2:size(dataset,1),size(dataset,2)]\n",
    "\n",
    "# Convert to regular values the output classes\n",
    "train_y = string.(train_y)\n",
    "\n",
    "# Show information of the transformed dataset\n",
    "println(\"Inputs size: \", size(train_x))\n",
    "println(\"Sample of inputs: \", train_x[1,:])\n",
    "println(\"Outputs size: \", size(train_y))\n",
    "println(\"Sample of Outputs: \", train_y[1])\n",
    "println(\"Unique Outputs: \", unique(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Hold Out function to split dataset into train and test\n",
    "indexs = holdOut(size(train_x,1),HOLD_OUT)\n",
    "\n",
    "train_input = train_x[indexs[1],:]\n",
    "train_output = vec(train_y[indexs[1],:])\n",
    "\n",
    "test_input = train_x[indexs[2],:]\n",
    "test_output = vec(train_y[indexs[2],:])\n",
    "\n",
    "#normalization after splitting, so test data cannot affect the train data and the first touch between them should be in predictions.\n",
    "train_input = normalizeMinMax!(train_input)\n",
    "test_input = normalizeMinMax!(test_input)\n",
    "\n",
    "# Show information about the splitted data\n",
    "println(\"Size original input data: \", size(train_x))\n",
    "println(\"Size original output data: \", size(train_y))\n",
    "\n",
    "println(\"Size train input data: \", size(train_input))\n",
    "println(\"Size train output data: \", size(train_output))\n",
    "\n",
    "println(\"Size test input data: \", size(test_input))\n",
    "println(\"Size test output data: \", size(test_output))\n",
    "\n",
    "println(\"Sample original input data: \", train_x[1,:])\n",
    "println(\"Sample train input data: \", train_input[1,:])\n",
    "println(\"Sample test input data: \", test_input[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66278936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the crossvalidation indexs for testing\n",
    "indexs = crossvalidation(train_output, NUM_FOLDS)\n",
    "kFoldIndices = convert(Vector{Int64}, indexs)\n",
    "\n",
    "# Show the crossvalidation size\n",
    "println(size(kFoldIndices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f9e00",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "This section contains all training of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cf6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model for Multi-layer Perceptron\n",
    "best_MLP = loadModel(MLP_FILE_PATH)\n",
    "# If model can not be loaded from disk, reload from code\n",
    "if isnothing(best_MLP)\n",
    "    best_MLP = get_Best_MLP(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Support Vector Machine\n",
    "best_SVM = loadModel(SVM_FILE_PATH)\n",
    "if isnothing(best_SVM)\n",
    "    best_SVM = get_Best_SVM(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Decision Tree\n",
    "best_DT = loadModel(DT_FILE_PATH)\n",
    "if isnothing(best_DT)\n",
    "    best_DT = get_Best_DT(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for K-Nearest Neighbor\n",
    "best_KNN = loadModel(KNN_FILE_PATH)\n",
    "if isnothing(best_KNN)\n",
    "    best_KNN = get_Best_KNN(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Gaussian Naive Bayes\n",
    "best_GB = loadModel(GB_FILE_PATH)\n",
    "if isnothing(best_GB)\n",
    "    best_GB = get_Best_GB(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Logistic Regression\n",
    "best_LR = loadModel(LR_FILE_PATH)\n",
    "if isnothing(best_LR)\n",
    "    best_LR = get_Best_LR(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Nearest centroid\n",
    "best_NC = loadModel(NC_FILE_PATH)\n",
    "if isnothing(best_NC)\n",
    "    best_NC = get_Best_NC(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Radius Neighbors\n",
    "best_RN = loadModel(RN_FILE_PATH)\n",
    "if isnothing(best_RN)\n",
    "    best_RN = get_Best_RN(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Ridge Regression\n",
    "best_RR = loadModel(RR_FILE_PATH)\n",
    "if isnothing(best_RR)\n",
    "    best_RR = get_Best_RR(train_input, train_output, kFoldIndices)\n",
    "end\n",
    "# Get the best model for Majority voting ensemble\n",
    "best_MV = loadModel(MV_FILE_PATH)\n",
    "if isnothing(best_MV)\n",
    "    best_MV = get_Best_MV(train_input, train_output)\n",
    "end\n",
    "# Get the best model for Weighted Majority voting ensemble\n",
    "best_WM = loadModel(WM_FILE_PATH)\n",
    "if isnothing(best_WM)\n",
    "    best_WM = get_Best_WM(train_input, train_output)\n",
    "end\n",
    "# Get the best model for Stacking ensemble\n",
    "best_ST = loadModel(ST_FILE_PATH)\n",
    "if isnothing(best_ST)\n",
    "    best_WM = get_Best_ST(train_input, train_output)\n",
    "end\n",
    "# Get the best model for Bagging ensemble\n",
    "best_BG = loadModel(BG_FILE_PATH)\n",
    "if isnothing(best_BG)\n",
    "    best_WM = get_Best_BG(train_input, train_output)\n",
    "end\n",
    "# Get the best model for boosting ADA ensemble\n",
    "best_BA = loadModel(BA_FILE_PATH)\n",
    "if isnothing(best_BA)\n",
    "    best_WM = get_Best_BA(train_input, train_output)\n",
    "end\n",
    "# Get the best model for boosting Gradient ensemble \n",
    "best_GR = loadModel(GR_FILE_PATH)\n",
    "if isnothing(best_GR)\n",
    "    best_WM = get_Best_GR(train_input, train_output)\n",
    "end\n",
    "# Get the best model for Random Forest ensemble\n",
    "best_RF = loadModel(RF_FILE_PATH)\n",
    "if isnothing(best_RF)\n",
    "    best_RF = get_Best_RF(train_input, train_output)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the test dataset to get the metrics of each model\n",
    "if RERUN_METRICS\n",
    "    testOutputs = predict(best_MLP, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Multi-layer Perceptron Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_SVM, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Support Vector Machine Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_DT, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Decision Tree Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_KNN, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"K-Nearest Neighbor Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_GB, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Gaussian Naive Bayes Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_LR, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Logistic Regression Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_NC, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Nearest centroid Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_RN, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Radius Neighbors Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_RR, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Ridge Regression Accuracy: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "    \n",
    "    testOutputs = predict(best_MV, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Majority voting ensemble: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "\n",
    "    testOutputs = predict(best_WM, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Weighted Majority voting ensemble: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "    \n",
    "    testOutputs = predict(best_ST, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Stacking ensemble: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "    \n",
    "    testOutputs = predict(best_BG, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Bagging ensemble: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "    \n",
    "    testOutputs = predict(best_BA, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Boosting ADA ensemble: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "    \n",
    "    testOutputs = predict(best_GR, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Boosting Gradient ensemble: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "    \n",
    "    testOutputs = predict(best_RF, test_input)\n",
    "    metrics = confusionMatrix(testOutputs, test_output, weighted=false)\n",
    "    println(\"Random Forest ensemble: \", metrics[1], \" Fscore: \", metrics[2])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077bb24-77b0-44f3-9dad-6afaffdf7744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
